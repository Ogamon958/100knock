{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lt7aty4qSRW"
   },
   "source": [
    "翻訳器の作成．\n",
    "英⇒日はwebから引用したものを利用.\n",
    "日⇒英は100本ノック98で作ったものを利用する.\n",
    "\n",
    "まずは必要なデータやライブラリをそろえます．\n",
    "\n",
    "参考 \n",
    "https://qiita.com/nymwa/items/2f39a34982aa9d71f10d  \n",
    "https://gist.github.com/nymwa/d584be8ed36b9513a31e31f5b8f50112  \n",
    "https://qiita.com/O-Kazu-O/items/5c0781913a1d033bea39"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ここから英→日の訓練　訓練は別サーバで行った"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 113063,
     "status": "ok",
     "timestamp": 1645978400837,
     "user": {
      "displayName": "小笠雄也",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3-7lYEXBfIfaYmq_UtMxNULG57MqI8cexF-rY=s64",
      "userId": "11557424356353414933"
     },
     "user_tz": -540
    },
    "id": "RmV_ca5uafqf",
    "outputId": "2c60a0db-70ad-486e-cd09-4d4b6f1a2890"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'light_enja2'...\n",
      "remote: Enumerating objects: 30, done.\u001b[K\n",
      "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
      "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
      "remote: Total 30 (delta 4), reused 30 (delta 4), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (30/30), done.\n",
      "Collecting sacremoses==0.0.35\n",
      "  Using cached sacremoses-0.0.35.tar.gz (859 kB)\n",
      "Collecting torch==1.9.0\n",
      "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 831.4 MB 2.7 kB/s \n",
      "\u001b[?25hCollecting fairseq==0.10.2\n",
      "  Downloading fairseq-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 55.8 MB/s \n",
      "\u001b[?25hCollecting sacrebleu==1.5.1\n",
      "  Downloading sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 3.1 MB/s \n",
      "\u001b[?25hCollecting sentencepiece==0.1.96\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 46.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->-r requirements.txt (line 1)) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->-r requirements.txt (line 1)) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->-r requirements.txt (line 2)) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2->-r requirements.txt (line 3)) (1.21.5)\n",
      "Collecting hydra-core\n",
      "  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
      "\u001b[K     |████████████████████████████████| 145 kB 61.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2->-r requirements.txt (line 3)) (1.15.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2->-r requirements.txt (line 3)) (2019.12.20)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2->-r requirements.txt (line 3)) (0.29.28)\n",
      "Collecting dataclasses\n",
      "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Collecting portalocker==2.0.0\n",
      "  Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==0.10.2->-r requirements.txt (line 3)) (2.21)\n",
      "Collecting omegaconf==2.1.*\n",
      "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
      "\u001b[K     |████████████████████████████████| 74 kB 3.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq==0.10.2->-r requirements.txt (line 3)) (5.4.0)\n",
      "Collecting antlr4-python3-runtime==4.8\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 58.1 MB/s \n",
      "\u001b[?25hCollecting PyYAML>=5.1.0\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 55.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core->fairseq==0.10.2->-r requirements.txt (line 3)) (3.7.0)\n",
      "Building wheels for collected packages: sacremoses, antlr4-python3-runtime\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.35-py3-none-any.whl size=883989 sha256=ac61d11f7a17cc2ea045169675ecba16ee948fc80feb18ef6de7419cae2213c1\n",
      "  Stored in directory: /root/.cache/pip/wheels/d1/ff/0e/e00ff1e22100702ac8b24e709551ae0fb29db9ffc843510a64\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=01314bd18d923980655348f32b30de5f2b8977ba075af3ecfd3a1effda6937e4\n",
      "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
      "Successfully built sacremoses antlr4-python3-runtime\n",
      "Installing collected packages: PyYAML, antlr4-python3-runtime, portalocker, omegaconf, torch, sacrebleu, hydra-core, dataclasses, sentencepiece, sacremoses, fairseq\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.10.0+cu111\n",
      "    Uninstalling torch-1.10.0+cu111:\n",
      "      Successfully uninstalled torch-1.10.0+cu111\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.9.0 which is incompatible.\n",
      "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.9.0 which is incompatible.\n",
      "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
      "Successfully installed PyYAML-6.0 antlr4-python3-runtime-4.8 dataclasses-0.6 fairseq-0.10.2 hydra-core-1.1.1 omegaconf-2.1.1 portalocker-2.0.0 sacrebleu-1.5.1 sacremoses-0.0.35 sentencepiece-0.1.96 torch-1.9.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "dataclasses",
         "pydevd_plugins"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!git clone https://github.com/nymwa/light_enja2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv light_enja2/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacremoses==0.0.35\n",
      "  Downloading sacremoses-0.0.35.tar.gz (859 kB)\n",
      "Collecting torch==1.9.0\n",
      "  Downloading torch-1.9.0-cp38-cp38-win_amd64.whl (222.0 MB)\n",
      "Collecting fairseq==0.10.2\n",
      "  Using cached fairseq-0.10.2.tar.gz (938 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\local\\Anaconda3\\python.exe' 'C:\\local\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\ogasa\\AppData\\Local\\Temp\\tmpjp5vbsqx'\n",
      "       cwd: C:\\Users\\ogasa\\AppData\\Local\\Temp\\pip-install-7kuvmah4\\fairseq\n",
      "  Complete output (31 lines):\n",
      "  Traceback (most recent call last):\n",
      "    File \"setup.py\", line 214, in <module>\n",
      "      do_setup(package_data)\n",
      "    File \"setup.py\", line 136, in do_setup\n",
      "      setup(\n",
      "    File \"C:\\Users\\ogasa\\AppData\\Local\\Temp\\pip-build-env-gtdq9seq\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 154, in setup\n",
      "      _install_setup_requires(attrs)\n",
      "    File \"C:\\Users\\ogasa\\AppData\\Local\\Temp\\pip-build-env-gtdq9seq\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 148, in _install_setup_requires\n",
      "      dist.fetch_build_eggs(dist.setup_requires)\n",
      "    File \"C:\\Users\\ogasa\\AppData\\Local\\Temp\\pip-build-env-gtdq9seq\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 62, in fetch_build_eggs\n",
      "      raise SetupRequirementsError(specifier_list)\n",
      "  setuptools.build_meta.SetupRequirementsError: ['cython', 'numpy', 'setuptools>=18.0']\n",
      "  \n",
      "  During handling of the above exception, another exception occurred:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\local\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\_in_process.py\", line 280, in <module>\n",
      "      main()\n",
      "    File \"C:\\local\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\_in_process.py\", line 263, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "    File \"C:\\local\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\_in_process.py\", line 114, in get_requires_for_build_wheel\n",
      "      return hook(config_settings)\n",
      "    File \"C:\\Users\\ogasa\\AppData\\Local\\Temp\\pip-build-env-gtdq9seq\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 177, in get_requires_for_build_wheel\n",
      "      return self._get_build_requires(\n",
      "    File \"C:\\Users\\ogasa\\AppData\\Local\\Temp\\pip-build-env-gtdq9seq\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 159, in _get_build_requires\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\ogasa\\AppData\\Local\\Temp\\pip-build-env-gtdq9seq\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 174, in run_setup\n",
      "      exec(compile(code, __file__, 'exec'), locals())\n",
      "    File \"setup.py\", line 217, in <module>\n",
      "      os.unlink(fairseq_examples)\n",
      "  PermissionError: [WinError 5] アクセスが拒否されました。: 'fairseq\\\\examples'\n",
      "  ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\local\\Anaconda3\\python.exe' 'C:\\local\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\ogasa\\AppData\\Local\\Temp\\tmpjp5vbsqx' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgFZmYSHqdld"
   },
   "source": [
    "データに対して前処理を行います\n",
    "\n",
    "ダウンロードした時点でデータセットは単語分割やトークン化がすでに施されています．\n",
    "マージ数8000のBPEでサブワードに分割します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 41959,
     "status": "ok",
     "timestamp": 1645978442789,
     "user": {
      "displayName": "小笠雄也",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3-7lYEXBfIfaYmq_UtMxNULG57MqI8cexF-rY=s64",
      "userId": "11557424356353414933"
     },
     "user_tz": -540
    },
    "id": "-VQQIdbqaxkJ",
    "outputId": "33615c07-292c-4c66-8826-a622f7a1cab2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ TRAIN_EN=corpus/train.en\n",
      "+ TRAIN_JA=corpus/train.ja\n",
      "+ VALID_EN=corpus/valid.en\n",
      "+ VALID_JA=corpus/valid.ja\n",
      "+ TEST_EN=corpus/test.en\n",
      "+ cat corpus/train.en corpus/train.ja\n",
      "+ python src/learn.py --input train.enja --prefix bpe --vocab-size 4000 --character-coverage 0.9995 --threads 1\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: train.enja\n",
      "  input_format: \n",
      "  model_prefix: bpe\n",
      "  model_type: BPE\n",
      "  vocab_size: 4000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 1\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: train.enja\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 200000 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=6286314\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9501% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1546\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999501\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 200000 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 200000\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 16208\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=110415 min_freq=268\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=31872 size=20 all=11962 active=1291 piece=in\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19776 size=40 all=12337 active=1666 piece=is\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14446 size=60 all=12924 active=2253 piece=▁と\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9019 size=80 all=13419 active=2748 piece=▁we\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7250 size=100 all=13708 active=3037 piece=▁on\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=7233 min_freq=474\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5610 size=120 all=14035 active=1322 piece=▁have\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4509 size=140 all=14435 active=1722 piece=os\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3861 size=160 all=14773 active=2060 piece=▁ある\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3339 size=180 all=15200 active=2487 piece=ea\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2840 size=200 all=15402 active=2689 piece=▁whe\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2837 min_freq=438\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2537 size=220 all=15746 active=1340 piece=▁それ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2304 size=240 all=16056 active=1650 piece=ck\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2115 size=260 all=16333 active=1927 piece=ame\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1953 size=280 all=16635 active=2229 piece=▁en\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1837 size=300 all=16838 active=2432 piece=▁会\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1835 min_freq=382\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1708 size=320 all=17092 active=1236 piece=▁!\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1613 size=340 all=17236 active=1380 piece=▁わ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1474 size=360 all=17401 active=1545 piece=▁好き\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1402 size=380 all=17560 active=1704 piece=▁もう\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1314 size=400 all=17757 active=1901 piece=ild\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1313 min_freq=347\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1249 size=420 all=17875 active=1107 piece=▁自分\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1199 size=440 all=18062 active=1294 piece=▁off\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1134 size=460 all=18227 active=1459 piece=itt\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1098 size=480 all=18323 active=1555 piece=▁時間\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1040 size=500 all=18479 active=1711 piece=▁車\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1039 min_freq=310\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1008 size=520 all=18622 active=1142 piece=▁テ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=979 size=540 all=18735 active=1255 piece=▁分\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=933 size=560 all=18818 active=1338 piece=▁friend\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=895 size=580 all=18995 active=1515 piece=ove\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=855 size=600 all=19102 active=1622 piece=own\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=852 min_freq=287\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=834 size=620 all=19239 active=1128 piece=▁明日\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=804 size=640 all=19349 active=1238 piece=▁plan\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=786 size=660 all=19437 active=1326 piece=▁本当\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=766 size=680 all=19509 active=1398 piece=▁同\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=740 size=700 all=19607 active=1496 piece=▁boy\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=739 min_freq=262\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=709 size=720 all=19734 active=1126 piece=ark\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=692 size=740 all=19814 active=1206 piece=▁week\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=668 size=760 all=19981 active=1373 piece=しく\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=645 size=780 all=20146 active=1538 piece=▁gr\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=622 size=800 all=20312 active=1704 piece=▁金\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=622 min_freq=242\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=604 size=820 all=20431 active=1127 piece=able\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=584 size=840 all=20540 active=1236 piece=▁聞い\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=564 size=860 all=20660 active=1356 piece=▁nothing\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=545 size=880 all=20738 active=1434 piece=▁働\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=526 size=900 all=20866 active=1562 piece=rest\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=525 min_freq=219\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=504 size=920 all=20955 active=1125 piece=▁count\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=491 size=940 all=21071 active=1241 piece=bod\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=482 size=960 all=21232 active=1402 piece=▁世\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=470 size=980 all=21365 active=1535 piece=▁news\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=457 size=1000 all=21444 active=1614 piece=ting\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=457 min_freq=200\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=447 size=1020 all=21514 active=1130 piece=▁days\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=437 size=1040 all=21568 active=1184 piece=▁パー\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=426 size=1060 all=21658 active=1274 piece=ope\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=417 size=1080 all=21729 active=1345 piece=cle\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=411 size=1100 all=21773 active=1389 piece=▁boston\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=411 min_freq=188\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=401 size=1120 all=21838 active=1154 piece=ible\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=390 size=1140 all=21968 active=1284 piece=ause\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=384 size=1160 all=22062 active=1378 piece=▁meeting\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=376 size=1180 all=22146 active=1462 piece=igh\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=371 size=1200 all=22235 active=1551 piece=▁切\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=371 min_freq=174\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=365 size=1220 all=22329 active=1197 piece=▁夜\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=359 size=1240 all=22356 active=1224 piece=▁会い\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=351 size=1260 all=22424 active=1292 piece=▁難\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=346 size=1280 all=22507 active=1375 piece=▁くる\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=338 size=1300 all=22571 active=1439 piece=ip\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=338 min_freq=163\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=329 size=1320 all=22646 active=1184 piece=▁うま\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=320 size=1340 all=22750 active=1288 piece=▁6\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=313 size=1360 all=22779 active=1317 piece=▁眠\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=309 size=1380 all=22826 active=1364 piece=ニス\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=305 size=1400 all=22905 active=1443 piece=▁alone\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=304 min_freq=152\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=299 size=1420 all=22982 active=1223 piece=▁food\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=294 size=1440 all=23017 active=1258 piece=▁場\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=290 size=1460 all=23102 active=1343 piece=▁afraid\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=285 size=1480 all=23154 active=1395 piece=tain\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=281 size=1500 all=23210 active=1451 piece=oon\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=281 min_freq=143\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=278 size=1520 all=23249 active=1194 piece=▁supp\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=274 size=1540 all=23328 active=1273 piece=▁both\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=269 size=1560 all=23429 active=1374 piece=uth\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=266 size=1580 all=23479 active=1424 piece=▁large\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=261 size=1600 all=23536 active=1481 piece=▁死ん\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=261 min_freq=134\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=256 size=1620 all=23563 active=1204 piece=▁座っ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=254 size=1640 all=23613 active=1254 piece=lain\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=251 size=1660 all=23672 active=1313 piece=▁知り\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=247 size=1680 all=23719 active=1360 piece=▁コン\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=243 size=1700 all=23787 active=1428 piece=▁意見\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=243 min_freq=125\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=240 size=1720 all=23841 active=1244 piece=▁足\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=237 size=1740 all=23893 active=1296 piece=▁free\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=232 size=1760 all=23923 active=1326 piece=▁願\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=229 size=1780 all=23978 active=1381 piece=▁速\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=226 size=1800 all=24025 active=1428 piece=▁short\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=226 min_freq=119\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=223 size=1820 all=24076 active=1250 piece=▁ele\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=220 size=1840 all=24134 active=1308 piece=▁then\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=217 size=1860 all=24166 active=1340 piece=っかり\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=214 size=1880 all=24208 active=1382 piece=▁読む\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=211 size=1900 all=24247 active=1421 piece=▁終わっ\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=211 min_freq=111\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=209 size=1920 all=24293 active=1259 piece=▁result\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=205 size=1940 all=24345 active=1311 piece=▁馬\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=203 size=1960 all=24381 active=1347 piece=▁日曜日\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=200 size=1980 all=24431 active=1397 piece=▁結果\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=197 size=2000 all=24451 active=1417 piece=▁靴\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=197 min_freq=106\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=195 size=2020 all=24488 active=1257 piece=▁cam\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=193 size=2040 all=24535 active=1304 piece=▁number\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=190 size=2060 all=24575 active=1344 piece=▁bor\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=188 size=2080 all=24623 active=1392 piece=ross\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=185 size=2100 all=24643 active=1412 piece=▁あい\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=185 min_freq=100\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=183 size=2120 all=24674 active=1259 piece=▁uncle\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=181 size=2140 all=24716 active=1301 piece=▁others\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=179 size=2160 all=24763 active=1347 piece=form\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=177 size=2180 all=24827 active=1411 piece=▁おも\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=175 size=2200 all=24849 active=1433 piece=▁making\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=174 min_freq=95\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=173 size=2220 all=24874 active=1268 piece=▁持ち\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=171 size=2240 all=24916 active=1310 piece=▁box\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=169 size=2260 all=24942 active=1336 piece=▁怒っ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=168 size=2280 all=24977 active=1371 piece=▁ter\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=166 size=2300 all=25035 active=1429 piece=here\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=166 min_freq=91\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=164 size=2320 all=25058 active=1272 piece=▁賛成\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=162 size=2340 all=25086 active=1300 piece=▁外出\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=161 size=2360 all=25122 active=1336 piece=▁テーブル\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=159 size=2380 all=25147 active=1361 piece=▁passed\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=157 size=2400 all=25213 active=1427 piece=▁paper\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=157 min_freq=87\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=155 size=2420 all=25251 active=1299 piece=▁account\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=152 size=2440 all=25275 active=1323 piece=▁招\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: bpe.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: bpe.vocab\n",
      "+ encode\n",
      "+ python src/encode.py --model bpe.model\n",
      "+ encode\n",
      "+ python src/encode.py --model bpe.model\n",
      "+ encode\n",
      "+ python src/encode.py --model bpe.model\n",
      "+ encode\n",
      "+ python src/encode.py --model bpe.model\n",
      "+ encode\n",
      "+ python src/encode.py --model bpe.model\n",
      "+ fairseq-preprocess -s en -t ja --trainpref train --validpref valid --destdir data-bin --joined-dictionary\n",
      "2022-02-27 16:09:49 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='en', srcdict=None, target_lang='ja', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='train', user_dir=None, validpref='valid', workers=1)\n",
      "2022-02-27 16:10:01 | INFO | fairseq_cli.preprocess | [en] Dictionary: 3888 types\n",
      "2022-02-27 16:10:07 | INFO | fairseq_cli.preprocess | [en] train.en: 100000 sents, 1149344 tokens, 0.0% replaced by <unk>\n",
      "2022-02-27 16:10:07 | INFO | fairseq_cli.preprocess | [en] Dictionary: 3888 types\n",
      "2022-02-27 16:10:08 | INFO | fairseq_cli.preprocess | [en] valid.en: 5000 sents, 57553 tokens, 0.0% replaced by <unk>\n",
      "2022-02-27 16:10:08 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 3888 types\n",
      "2022-02-27 16:10:15 | INFO | fairseq_cli.preprocess | [ja] train.ja: 100000 sents, 1367026 tokens, 0.0% replaced by <unk>\n",
      "2022-02-27 16:10:15 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 3888 types\n",
      "2022-02-27 16:10:15 | INFO | fairseq_cli.preprocess | [ja] valid.ja: 5000 sents, 68289 tokens, 0.0% replaced by <unk>\n",
      "2022-02-27 16:10:15 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin\n"
     ]
    }
   ],
   "source": [
    "! bash preproc.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sr70ETxTq2Pg"
   },
   "source": [
    "学習を行います．\n",
    "\n",
    "少ないデータでかつかなり軽量なモデルでの学習ですが，10分ぐらいかかります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 791930,
     "status": "ok",
     "timestamp": 1645979234709,
     "user": {
      "displayName": "小笠雄也",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3-7lYEXBfIfaYmq_UtMxNULG57MqI8cexF-rY=s64",
      "userId": "11557424356353414933"
     },
     "user_tz": -540
    },
    "id": "6VyE7idzbARO",
    "outputId": "b5913755-3d4c-4a32-9774-bb626d002558",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-27 16:10:16 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.999)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=4, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=4, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.6, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.002], lr_scheduler='inverse_sqrt', max_epoch=10, max_source_positions=1024, max_target_positions=1024, max_tokens=4000, max_tokens_valid=4000, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=10, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=1e-07, warmup_updates=2000, weight_decay=0.01, zero_sharding='none')\n",
      "2022-02-27 16:10:16 | INFO | fairseq.tasks.translation | [en] dictionary: 3888 types\n",
      "2022-02-27 16:10:16 | INFO | fairseq.tasks.translation | [ja] dictionary: 3888 types\n",
      "2022-02-27 16:10:16 | INFO | fairseq.data.data_utils | loaded 5000 examples from: data-bin/valid.en-ja.en\n",
      "2022-02-27 16:10:16 | INFO | fairseq.data.data_utils | loaded 5000 examples from: data-bin/valid.en-ja.ja\n",
      "2022-02-27 16:10:16 | INFO | fairseq.tasks.translation | data-bin valid en-ja 5000 examples\n",
      "2022-02-27 16:10:17 | INFO | fairseq_cli.train | TransformerModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(3888, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(3888, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (output_projection): Linear(in_features=512, out_features=3888, bias=False)\n",
      "  )\n",
      ")\n",
      "2022-02-27 16:10:17 | INFO | fairseq_cli.train | task: translation (TranslationTask)\n",
      "2022-02-27 16:10:17 | INFO | fairseq_cli.train | model: transformer (TransformerModel)\n",
      "2022-02-27 16:10:17 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)\n",
      "2022-02-27 16:10:17 | INFO | fairseq_cli.train | num. model params: 23021568 (num. trained: 23021568)\n",
      "2022-02-27 16:10:23 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight\n",
      "2022-02-27 16:10:23 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight\n",
      "2022-02-27 16:10:23 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2022-02-27 16:10:23 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.756 GB ; name = Tesla T4                                \n",
      "2022-02-27 16:10:23 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2022-02-27 16:10:23 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
      "2022-02-27 16:10:23 | INFO | fairseq_cli.train | max tokens per GPU = 4000 and max sentences per GPU = None\n",
      "2022-02-27 16:10:23 | INFO | fairseq.trainer | no existing checkpoint found checkpoints/checkpoint_last.pt\n",
      "2022-02-27 16:10:23 | INFO | fairseq.trainer | loading train data for epoch 1\n",
      "2022-02-27 16:10:23 | INFO | fairseq.data.data_utils | loaded 100000 examples from: data-bin/train.en-ja.en\n",
      "2022-02-27 16:10:23 | INFO | fairseq.data.data_utils | loaded 100000 examples from: data-bin/train.en-ja.ja\n",
      "2022-02-27 16:10:23 | INFO | fairseq.tasks.translation | data-bin train en-ja 100000 examples\n",
      "2022-02-27 16:10:23 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16\n",
      "epoch 001:   0% 0/368 [00:00<?, ?it/s]2022-02-27 16:10:23 | INFO | fairseq.trainer | begin training epoch 1\n",
      "/usr/local/lib/python3.7/dist-packages/fairseq/utils.py:342: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
      "  \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"\n",
      "epoch 001: 100% 367/368 [01:13<00:00,  5.17it/s, loss=10.436, nll_loss=7.364, ppl=164.78, wps=18281.8, ups=4.93, wpb=3706.5, bsz=263, num_updates=300, lr=0.000300085, gnorm=0.385, clip=0, train_wall=20, wall=61]2022-02-27 16:11:37 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:   0% 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:   4% 1/25 [00:00<00:03,  7.49it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  12% 3/25 [00:00<00:01, 12.68it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  20% 5/25 [00:00<00:01, 14.40it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  28% 7/25 [00:00<00:01, 15.43it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  36% 9/25 [00:00<00:01, 15.86it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  44% 11/25 [00:00<00:00, 15.83it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  52% 13/25 [00:00<00:00, 15.98it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  60% 15/25 [00:00<00:00, 15.82it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  68% 17/25 [00:01<00:00, 15.76it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  76% 19/25 [00:01<00:00, 15.94it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  84% 21/25 [00:01<00:00, 16.41it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  92% 23/25 [00:01<00:00, 16.06it/s]\u001b[A\n",
      "                                                                        \u001b[A2022-02-27 16:11:39 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.185 | nll_loss 6.126 | ppl 69.84 | wps 45189.9 | wpb 2731.6 | bsz 200 | num_updates 368\n",
      "2022-02-27 16:11:39 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
      "2022-02-27 16:11:39 | INFO | train | epoch 001 | loss 10.923 | nll_loss 8.426 | ppl 343.92 | wps 18155.3 | ups 4.89 | wpb 3714.7 | bsz 271.7 | num_updates 368 | lr 0.000368082 | gnorm 0.781 | clip 10.9 | train_wall 73 | wall 76\n",
      "epoch 002:   0% 0/368 [00:00<?, ?it/s]2022-02-27 16:11:39 | INFO | fairseq.trainer | begin training epoch 2\n",
      "epoch 002: 100% 367/368 [01:15<00:00,  5.06it/s, loss=9.75, nll_loss=5.363, ppl=41.14, wps=17854, ups=4.88, wpb=3657.6, bsz=267.4, num_updates=700, lr=0.000700065, gnorm=0.347, clip=0, train_wall=20, wall=145]2022-02-27 16:12:55 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 002 | valid on 'valid' subset:   0% 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:   4% 1/25 [00:00<00:03,  7.47it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  12% 3/25 [00:00<00:01, 12.69it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  20% 5/25 [00:00<00:01, 13.81it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  28% 7/25 [00:00<00:01, 15.13it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  36% 9/25 [00:00<00:01, 15.58it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  44% 11/25 [00:00<00:00, 15.55it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  52% 13/25 [00:00<00:00, 15.67it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  60% 15/25 [00:01<00:00, 15.37it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  68% 17/25 [00:01<00:00, 15.54it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  76% 19/25 [00:01<00:00, 15.76it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  84% 21/25 [00:01<00:00, 16.29it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  92% 23/25 [00:01<00:00, 16.00it/s]\u001b[A\n",
      "                                                                        \u001b[A2022-02-27 16:12:56 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 9.573 | nll_loss 4.598 | ppl 24.22 | wps 44551.2 | wpb 2731.6 | bsz 200 | num_updates 736\n",
      "2022-02-27 16:12:56 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
      "2022-02-27 16:12:56 | INFO | train | epoch 002 | loss 9.887 | nll_loss 5.763 | ppl 54.3 | wps 17602.5 | ups 4.74 | wpb 3714.7 | bsz 271.7 | num_updates 736 | lr 0.000736063 | gnorm 0.37 | clip 0 | train_wall 75 | wall 154\n",
      "epoch 003:   0% 0/368 [00:00<?, ?it/s]2022-02-27 16:12:57 | INFO | fairseq.trainer | begin training epoch 3\n",
      "epoch 003: 100% 367/368 [01:15<00:00,  4.88it/s, loss=9.42, nll_loss=4.459, ppl=22, wps=18156.5, ups=4.87, wpb=3729.9, bsz=272.7, num_updates=1100, lr=0.00110005, gnorm=0.292, clip=0, train_wall=20, wall=229]2022-02-27 16:14:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 003 | valid on 'valid' subset:   0% 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset:   4% 1/25 [00:00<00:03,  7.61it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset:  12% 3/25 [00:00<00:01, 12.80it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset:  20% 5/25 [00:00<00:01, 14.35it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset:  28% 7/25 [00:00<00:01, 15.40it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset:  36% 9/25 [00:00<00:01, 15.76it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset:  44% 11/25 [00:00<00:00, 15.59it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset:  52% 13/25 [00:00<00:00, 15.62it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset:  60% 15/25 [00:01<00:00, 15.36it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset:  68% 17/25 [00:01<00:00, 15.43it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset:  76% 19/25 [00:01<00:00, 15.66it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset:  84% 21/25 [00:01<00:00, 16.17it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset:  92% 23/25 [00:01<00:00, 15.90it/s]\u001b[A\n",
      "                                                                        \u001b[A2022-02-27 16:14:14 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 9.349 | nll_loss 3.844 | ppl 14.36 | wps 44615.4 | wpb 2731.6 | bsz 200 | num_updates 1104\n",
      "2022-02-27 16:14:14 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
      "2022-02-27 16:14:14 | INFO | train | epoch 003 | loss 9.494 | nll_loss 4.655 | ppl 25.2 | wps 17652 | ups 4.75 | wpb 3714.7 | bsz 271.7 | num_updates 1104 | lr 0.00110404 | gnorm 0.302 | clip 0 | train_wall 75 | wall 231\n",
      "epoch 004:   0% 0/368 [00:00<?, ?it/s]2022-02-27 16:14:14 | INFO | fairseq.trainer | begin training epoch 4\n",
      "epoch 004: 100% 367/368 [01:15<00:00,  5.10it/s, loss=9.306, nll_loss=4.165, ppl=17.94, wps=18107.7, ups=4.84, wpb=3739, bsz=268.7, num_updates=1400, lr=0.00140003, gnorm=0.234, clip=0, train_wall=20, wall=292]2022-02-27 16:15:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 004 | valid on 'valid' subset:   0% 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:   4% 1/25 [00:00<00:03,  7.09it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  12% 3/25 [00:00<00:01, 12.25it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  20% 5/25 [00:00<00:01, 13.97it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  28% 7/25 [00:00<00:01, 15.18it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  36% 9/25 [00:00<00:01, 15.34it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  44% 11/25 [00:00<00:00, 15.29it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  52% 13/25 [00:00<00:00, 15.47it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  60% 15/25 [00:01<00:00, 15.34it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  68% 17/25 [00:01<00:00, 15.42it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  76% 19/25 [00:01<00:00, 15.64it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  84% 21/25 [00:01<00:00, 16.16it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  92% 23/25 [00:01<00:00, 15.80it/s]\u001b[A\n",
      "                                                                        \u001b[A2022-02-27 16:15:31 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 9.204 | nll_loss 3.576 | ppl 11.93 | wps 44327.2 | wpb 2731.6 | bsz 200 | num_updates 1472\n",
      "2022-02-27 16:15:31 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
      "2022-02-27 16:15:31 | INFO | train | epoch 004 | loss 9.315 | nll_loss 4.187 | ppl 18.22 | wps 17659.8 | ups 4.75 | wpb 3714.7 | bsz 271.7 | num_updates 1472 | lr 0.00147203 | gnorm 0.248 | clip 0 | train_wall 75 | wall 309\n",
      "epoch 005:   0% 0/368 [00:00<?, ?it/s]2022-02-27 16:15:31 | INFO | fairseq.trainer | begin training epoch 5\n",
      "epoch 005: 100% 367/368 [01:18<00:00,  4.97it/s, loss=9.2, nll_loss=3.904, ppl=14.97, wps=17643.3, ups=4.73, wpb=3733.2, bsz=270.6, num_updates=1800, lr=0.00180001, gnorm=0.2, clip=0, train_wall=21, wall=379]2022-02-27 16:16:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 005 | valid on 'valid' subset:   0% 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset:   4% 1/25 [00:00<00:02,  8.08it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset:  12% 3/25 [00:00<00:01, 13.06it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset:  20% 5/25 [00:00<00:01, 14.36it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset:  28% 7/25 [00:00<00:01, 15.27it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset:  36% 9/25 [00:00<00:01, 15.69it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset:  44% 11/25 [00:00<00:00, 15.63it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset:  52% 13/25 [00:00<00:00, 15.77it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset:  60% 15/25 [00:01<00:00, 15.39it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset:  68% 17/25 [00:01<00:00, 15.59it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset:  76% 19/25 [00:01<00:00, 15.82it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset:  84% 21/25 [00:01<00:00, 16.36it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset:  92% 23/25 [00:01<00:00, 16.03it/s]\u001b[A\n",
      "                                                                        \u001b[A2022-02-27 16:16:51 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 9.151 | nll_loss 3.391 | ppl 10.49 | wps 44903.2 | wpb 2731.6 | bsz 200 | num_updates 1840\n",
      "2022-02-27 16:16:51 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
      "2022-02-27 16:16:51 | INFO | train | epoch 005 | loss 9.219 | nll_loss 3.948 | ppl 15.44 | wps 17118.5 | ups 4.61 | wpb 3714.7 | bsz 271.7 | num_updates 1840 | lr 0.00184001 | gnorm 0.214 | clip 0 | train_wall 77 | wall 389\n",
      "epoch 006:   0% 0/368 [00:00<?, ?it/s]2022-02-27 16:16:51 | INFO | fairseq.trainer | begin training epoch 6\n",
      "epoch 006: 100% 367/368 [01:16<00:00,  4.71it/s, loss=9.118, nll_loss=3.706, ppl=13.05, wps=18123.8, ups=4.8, wpb=3775.9, bsz=279.8, num_updates=2200, lr=0.00190693, gnorm=0.169, clip=0, train_wall=21, wall=463]2022-02-27 16:18:08 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 006 | valid on 'valid' subset:   0% 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 006 | valid on 'valid' subset:   4% 1/25 [00:00<00:06,  3.78it/s]\u001b[A\n",
      "epoch 006 | valid on 'valid' subset:  12% 3/25 [00:00<00:02,  8.76it/s]\u001b[A\n",
      "epoch 006 | valid on 'valid' subset:  20% 5/25 [00:00<00:01, 11.27it/s]\u001b[A\n",
      "epoch 006 | valid on 'valid' subset:  28% 7/25 [00:00<00:01, 12.96it/s]\u001b[A\n",
      "epoch 006 | valid on 'valid' subset:  36% 9/25 [00:00<00:01, 13.95it/s]\u001b[A\n",
      "epoch 006 | valid on 'valid' subset:  44% 11/25 [00:00<00:00, 14.45it/s]\u001b[A\n",
      "epoch 006 | valid on 'valid' subset:  52% 13/25 [00:01<00:00, 14.76it/s]\u001b[A\n",
      "epoch 006 | valid on 'valid' subset:  60% 15/25 [00:01<00:00, 14.64it/s]\u001b[A\n",
      "epoch 006 | valid on 'valid' subset:  68% 17/25 [00:01<00:00, 14.94it/s]\u001b[A\n",
      "epoch 006 | valid on 'valid' subset:  76% 19/25 [00:01<00:00, 15.32it/s]\u001b[A\n",
      "epoch 006 | valid on 'valid' subset:  84% 21/25 [00:01<00:00, 15.93it/s]\u001b[A\n",
      "epoch 006 | valid on 'valid' subset:  92% 23/25 [00:01<00:00, 15.71it/s]\u001b[A\n",
      "                                                                        \u001b[A2022-02-27 16:18:09 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 9.066 | nll_loss 3.239 | ppl 9.44 | wps 44401.9 | wpb 2731.6 | bsz 200 | num_updates 2208\n",
      "2022-02-27 16:18:09 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)\n",
      "2022-02-27 16:18:09 | INFO | train | epoch 006 | loss 9.144 | nll_loss 3.763 | ppl 13.57 | wps 17481 | ups 4.71 | wpb 3714.7 | bsz 271.7 | num_updates 2208 | lr 0.00190347 | gnorm 0.182 | clip 0 | train_wall 75 | wall 467\n",
      "epoch 007:   0% 0/368 [00:00<?, ?it/s]2022-02-27 16:18:09 | INFO | fairseq.trainer | begin training epoch 7\n",
      "epoch 007: 100% 367/368 [01:15<00:00,  4.70it/s, loss=9.055, nll_loss=3.545, ppl=11.67, wps=17397.8, ups=4.73, wpb=3678.8, bsz=268, num_updates=2500, lr=0.00178885, gnorm=0.152, clip=0, train_wall=21, wall=528]2022-02-27 16:19:26 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 007 | valid on 'valid' subset:   0% 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 007 | valid on 'valid' subset:   4% 1/25 [00:00<00:03,  7.72it/s]\u001b[A\n",
      "epoch 007 | valid on 'valid' subset:  12% 3/25 [00:00<00:01, 12.48it/s]\u001b[A\n",
      "epoch 007 | valid on 'valid' subset:  20% 5/25 [00:00<00:01, 13.98it/s]\u001b[A\n",
      "epoch 007 | valid on 'valid' subset:  28% 7/25 [00:00<00:01, 15.05it/s]\u001b[A\n",
      "epoch 007 | valid on 'valid' subset:  36% 9/25 [00:00<00:01, 15.32it/s]\u001b[A\n",
      "epoch 007 | valid on 'valid' subset:  44% 11/25 [00:00<00:00, 15.25it/s]\u001b[A\n",
      "epoch 007 | valid on 'valid' subset:  52% 13/25 [00:00<00:00, 15.50it/s]\u001b[A\n",
      "epoch 007 | valid on 'valid' subset:  60% 15/25 [00:01<00:00, 15.10it/s]\u001b[A\n",
      "epoch 007 | valid on 'valid' subset:  68% 17/25 [00:01<00:00, 15.31it/s]\u001b[A\n",
      "epoch 007 | valid on 'valid' subset:  76% 19/25 [00:01<00:00, 15.58it/s]\u001b[A\n",
      "epoch 007 | valid on 'valid' subset:  84% 21/25 [00:01<00:00, 16.08it/s]\u001b[A\n",
      "epoch 007 | valid on 'valid' subset:  92% 23/25 [00:01<00:00, 15.86it/s]\u001b[A\n",
      "                                                                        \u001b[A2022-02-27 16:19:27 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 9.002 | nll_loss 3.095 | ppl 8.55 | wps 44163.4 | wpb 2731.6 | bsz 200 | num_updates 2576\n",
      "2022-02-27 16:19:27 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)\n",
      "2022-02-27 16:19:27 | INFO | train | epoch 007 | loss 9.054 | nll_loss 3.54 | ppl 11.63 | wps 17563 | ups 4.73 | wpb 3714.7 | bsz 271.7 | num_updates 2576 | lr 0.00176227 | gnorm 0.154 | clip 0 | train_wall 75 | wall 545\n",
      "epoch 008:   0% 0/368 [00:00<?, ?it/s]2022-02-27 16:19:27 | INFO | fairseq.trainer | begin training epoch 8\n",
      "epoch 008: 100% 367/368 [01:16<00:00,  5.00it/s, loss=8.981, nll_loss=3.363, ppl=10.29, wps=18321.7, ups=4.84, wpb=3788, bsz=270.8, num_updates=2900, lr=0.00166091, gnorm=0.136, clip=0, train_wall=20, wall=613]2022-02-27 16:20:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 008 | valid on 'valid' subset:   0% 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 008 | valid on 'valid' subset:   4% 1/25 [00:00<00:03,  7.76it/s]\u001b[A\n",
      "epoch 008 | valid on 'valid' subset:  12% 3/25 [00:00<00:01, 12.97it/s]\u001b[A\n",
      "epoch 008 | valid on 'valid' subset:  20% 5/25 [00:00<00:01, 14.45it/s]\u001b[A\n",
      "epoch 008 | valid on 'valid' subset:  28% 7/25 [00:00<00:01, 15.36it/s]\u001b[A\n",
      "epoch 008 | valid on 'valid' subset:  36% 9/25 [00:00<00:01, 15.73it/s]\u001b[A\n",
      "epoch 008 | valid on 'valid' subset:  44% 11/25 [00:00<00:00, 15.63it/s]\u001b[A\n",
      "epoch 008 | valid on 'valid' subset:  52% 13/25 [00:00<00:00, 15.83it/s]\u001b[A\n",
      "epoch 008 | valid on 'valid' subset:  60% 15/25 [00:00<00:00, 15.52it/s]\u001b[A\n",
      "epoch 008 | valid on 'valid' subset:  68% 17/25 [00:01<00:00, 15.65it/s]\u001b[A\n",
      "epoch 008 | valid on 'valid' subset:  76% 19/25 [00:01<00:00, 15.90it/s]\u001b[A\n",
      "epoch 008 | valid on 'valid' subset:  84% 21/25 [00:01<00:00, 16.34it/s]\u001b[A\n",
      "epoch 008 | valid on 'valid' subset:  92% 23/25 [00:01<00:00, 16.01it/s]\u001b[A\n",
      "                                                                        \u001b[A2022-02-27 16:20:46 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 8.968 | nll_loss 2.947 | ppl 7.71 | wps 44821.5 | wpb 2731.6 | bsz 200 | num_updates 2944\n",
      "2022-02-27 16:20:46 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)\n",
      "2022-02-27 16:20:46 | INFO | train | epoch 008 | loss 8.986 | nll_loss 3.372 | ppl 10.35 | wps 17406.2 | ups 4.69 | wpb 3714.7 | bsz 271.7 | num_updates 2944 | lr 0.00164845 | gnorm 0.141 | clip 0 | train_wall 76 | wall 623\n",
      "epoch 009:   0% 0/368 [00:00<?, ?it/s]2022-02-27 16:20:46 | INFO | fairseq.trainer | begin training epoch 9\n",
      "epoch 009: 100% 367/368 [01:16<00:00,  5.15it/s, loss=8.929, nll_loss=3.235, ppl=9.42, wps=17720, ups=4.69, wpb=3781.6, bsz=279.5, num_updates=3300, lr=0.001557, gnorm=0.129, clip=0, train_wall=21, wall=697]2022-02-27 16:22:03 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 009 | valid on 'valid' subset:   0% 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 009 | valid on 'valid' subset:   4% 1/25 [00:00<00:02,  8.07it/s]\u001b[A\n",
      "epoch 009 | valid on 'valid' subset:  12% 3/25 [00:00<00:01, 12.13it/s]\u001b[A\n",
      "epoch 009 | valid on 'valid' subset:  20% 5/25 [00:00<00:01, 13.92it/s]\u001b[A\n",
      "epoch 009 | valid on 'valid' subset:  28% 7/25 [00:00<00:01, 14.46it/s]\u001b[A\n",
      "epoch 009 | valid on 'valid' subset:  36% 9/25 [00:00<00:01, 14.87it/s]\u001b[A\n",
      "epoch 009 | valid on 'valid' subset:  44% 11/25 [00:00<00:00, 15.12it/s]\u001b[A\n",
      "epoch 009 | valid on 'valid' subset:  52% 13/25 [00:00<00:00, 15.27it/s]\u001b[A\n",
      "epoch 009 | valid on 'valid' subset:  60% 15/25 [00:01<00:00, 15.10it/s]\u001b[A\n",
      "epoch 009 | valid on 'valid' subset:  68% 17/25 [00:01<00:00, 15.29it/s]\u001b[A\n",
      "epoch 009 | valid on 'valid' subset:  76% 19/25 [00:01<00:00, 15.58it/s]\u001b[A\n",
      "epoch 009 | valid on 'valid' subset:  84% 21/25 [00:01<00:00, 16.06it/s]\u001b[A\n",
      "epoch 009 | valid on 'valid' subset:  92% 23/25 [00:01<00:00, 15.75it/s]\u001b[A\n",
      "                                                                        \u001b[A2022-02-27 16:22:04 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 8.929 | nll_loss 2.839 | ppl 7.16 | wps 43390.6 | wpb 2731.6 | bsz 200 | num_updates 3312\n",
      "2022-02-27 16:22:04 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)\n",
      "2022-02-27 16:22:04 | INFO | train | epoch 009 | loss 8.934 | nll_loss 3.243 | ppl 9.47 | wps 17438.4 | ups 4.69 | wpb 3714.7 | bsz 271.7 | num_updates 3312 | lr 0.00155417 | gnorm 0.132 | clip 0 | train_wall 76 | wall 701\n",
      "epoch 010:   0% 0/368 [00:00<?, ?it/s]2022-02-27 16:22:04 | INFO | fairseq.trainer | begin training epoch 10\n",
      "epoch 010: 100% 367/368 [01:16<00:00,  5.06it/s, loss=8.903, nll_loss=3.167, ppl=8.98, wps=17856.9, ups=4.75, wpb=3759.2, bsz=271.4, num_updates=3600, lr=0.00149071, gnorm=0.13, clip=0, train_wall=21, wall=761]2022-02-27 16:23:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 010 | valid on 'valid' subset:   0% 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 010 | valid on 'valid' subset:   4% 1/25 [00:00<00:03,  7.16it/s]\u001b[A\n",
      "epoch 010 | valid on 'valid' subset:  12% 3/25 [00:00<00:01, 12.36it/s]\u001b[A\n",
      "epoch 010 | valid on 'valid' subset:  20% 5/25 [00:00<00:01, 13.92it/s]\u001b[A\n",
      "epoch 010 | valid on 'valid' subset:  28% 7/25 [00:00<00:01, 15.09it/s]\u001b[A\n",
      "epoch 010 | valid on 'valid' subset:  36% 9/25 [00:00<00:01, 15.49it/s]\u001b[A\n",
      "epoch 010 | valid on 'valid' subset:  44% 11/25 [00:00<00:00, 15.52it/s]\u001b[A\n",
      "epoch 010 | valid on 'valid' subset:  52% 13/25 [00:00<00:00, 15.60it/s]\u001b[A\n",
      "epoch 010 | valid on 'valid' subset:  60% 15/25 [00:01<00:00, 15.28it/s]\u001b[A\n",
      "epoch 010 | valid on 'valid' subset:  68% 17/25 [00:01<00:00, 15.45it/s]\u001b[A\n",
      "epoch 010 | valid on 'valid' subset:  76% 19/25 [00:01<00:00, 15.62it/s]\u001b[A\n",
      "epoch 010 | valid on 'valid' subset:  84% 21/25 [00:01<00:00, 16.12it/s]\u001b[A\n",
      "epoch 010 | valid on 'valid' subset:  92% 23/25 [00:01<00:00, 15.85it/s]\u001b[A\n",
      "                                                                        \u001b[A2022-02-27 16:23:22 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 8.91 | nll_loss 2.75 | ppl 6.73 | wps 44157.3 | wpb 2731.6 | bsz 200 | num_updates 3680\n",
      "2022-02-27 16:23:22 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-27 16:23:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint10.pt (epoch 10 @ 3680 updates, score 8.91) (writing took 4.454531346000067 seconds)\n",
      "2022-02-27 16:23:27 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)\n",
      "2022-02-27 16:23:27 | INFO | train | epoch 010 | loss 8.894 | nll_loss 3.144 | ppl 8.84 | wps 16585.3 | ups 4.46 | wpb 3714.7 | bsz 271.7 | num_updates 3680 | lr 0.00147442 | gnorm 0.128 | clip 0 | train_wall 75 | wall 784\n",
      "2022-02-27 16:23:27 | INFO | fairseq_cli.train | done training in 783.5 seconds\n"
     ]
    }
   ],
   "source": [
    "!fairseq-train \\\n",
    "    data-bin \\\n",
    "    --save-interval 10 \\\n",
    "    --max-epoch 10 \\\n",
    "    --update-freq 1 \\\n",
    "    --max-tokens 4000 \\\n",
    "    --arch transformer \\\n",
    "    --encoder-normalize-before \\\n",
    "    --decoder-normalize-before \\\n",
    "    --encoder-embed-dim 512 \\\n",
    "    --encoder-ffn-embed-dim 1024 \\\n",
    "    --encoder-attention-heads 4 \\\n",
    "    --encoder-layers 4 \\\n",
    "    --decoder-embed-dim 512 \\\n",
    "    --decoder-ffn-embed-dim 1024 \\\n",
    "    --decoder-attention-heads 4 \\\n",
    "    --decoder-layers 4 \\\n",
    "    --share-all-embeddings \\\n",
    "    --dropout 0.3 \\\n",
    "    --optimizer adam \\\n",
    "    --adam-betas '(0.9, 0.999)' \\\n",
    "    --lr 0.002 \\\n",
    "    --lr-scheduler inverse_sqrt \\\n",
    "    --warmup-updates 2000 \\\n",
    "    --warmup-init-lr 1e-07 \\\n",
    "    --clip-norm 1.0 \\\n",
    "    --weight-decay 0.01 \\\n",
    "    --criterion label_smoothed_cross_entropy \\\n",
    "    --label-smoothing 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMGSzREErEqV"
   },
   "source": [
    "テストデータで翻訳を行い，その性能を評価します．\n",
    "\n",
    "評価尺度BLEUで30ぐらい出ると思います．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29747,
     "status": "ok",
     "timestamp": 1645979264452,
     "user": {
      "displayName": "小笠雄也",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3-7lYEXBfIfaYmq_UtMxNULG57MqI8cexF-rY=s64",
      "userId": "11557424356353414933"
     },
     "user_tz": -540
    },
    "id": "H989es1arIyX",
    "outputId": "c9eda6cd-d694-46e7-edb4-da88270d594c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "BLEU+case.mixed+numrefs.1+smooth.exp+tok.13a+version.1.5.1 = 30.6 66.3/41.9/27.1/18.6 (BP = 0.891 ratio = 0.896 hyp_len = 45908 ref_len = 51230)\n"
     ]
    }
   ],
   "source": [
    "! fairseq-interactive data-bin \\\n",
    "    --buffer-size 1024 \\\n",
    "    --batch-size 128 \\\n",
    "    --path checkpoints/checkpoint10.pt \\\n",
    "    --beam 5 \\\n",
    "    --lenpen 0.6 \\\n",
    "    < test.en \\\n",
    "    | grep '^H' \\\n",
    "    | cut -f 3 \\\n",
    "    | python src/decode.py \\\n",
    "    | tee output.txt \\\n",
    "    | sacrebleu corpus/test.ja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGx0a5Vxrlgb"
   },
   "source": [
    "翻訳結果と正解データの冒頭10文です．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1645979264452,
     "user": {
      "displayName": "小笠雄也",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3-7lYEXBfIfaYmq_UtMxNULG57MqI8cexF-rY=s64",
      "userId": "11557424356353414933"
     },
     "user_tz": -540
    },
    "id": "h7neQQskrNRl",
    "outputId": "45efe2c3-a43e-4842-8c11-83df622dad50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> output.txt <==\n",
      "彼女 の 母 は 美しい 女性 です 。\n",
      "畑 に は 6 人 の 羊 が い た 。\n",
      "今朝 は 散歩 の 間 に 大きな 写真 を 撮る こと が でき た 。\n",
      "今晩 電話 し ます 。\n",
      "彼女 は 本 の 虫 だ 。\n",
      "式 は 終わっ た 。\n",
      "私 は 彼 に 前日 自分 で 楽しん だ か どう か 尋ね た 。\n",
      "彼 は 注意 し て い ない 。\n",
      "列車 は いつも 定刻 に いる 。\n",
      "2 時 に 出発 すれ ば 、 彼 ら は 6 時 に 着く べき だ 。\n",
      "\n",
      "==> corpus/test.ja <==\n",
      "彼女 の お母さん は きれい な 女 の 人 です 。\n",
      "野原 に は 六 頭 の 羊 が い た 。\n",
      "この 朝 の 散歩 で とても 素晴らしい 写真 を 撮る こと が でき た 。\n",
      "今夜 電話 し ます 。\n",
      "彼女 は いわゆる 本 の 虫 です 。\n",
      "式典 は 終わり まし た 。\n",
      "昨日 は 楽しかっ た か 、 と 私 は 彼 に 尋ね た 。\n",
      "彼 に は 心配 事 が ない 。\n",
      "その 列車 は いつも 時刻 通り だ 。\n",
      "2 時 に 出発 し たら 、 6 時 に は つく はず だ 。\n"
     ]
    }
   ],
   "source": [
    "! head output.txt corpus/test.ja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXH6CjmZrzKH"
   },
   "source": [
    "## ここまで訓練\n",
    "### ここからlocalで実行するために必要なものをインストールする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fairseq==0.10.0 in c:\\local\\anaconda3\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy in c:\\local\\anaconda3\\lib\\site-packages (from fairseq==0.10.0) (1.21.5)\n",
      "Requirement already satisfied: dataclasses in c:\\local\\anaconda3\\lib\\site-packages (from fairseq==0.10.0) (0.6)\n",
      "Requirement already satisfied: editdistance in c:\\local\\anaconda3\\lib\\site-packages (from fairseq==0.10.0) (0.6.0)\n",
      "Requirement already satisfied: cython in c:\\local\\anaconda3\\lib\\site-packages (from fairseq==0.10.0) (0.29.21)\n",
      "Requirement already satisfied: tqdm in c:\\local\\anaconda3\\lib\\site-packages (from fairseq==0.10.0) (4.50.2)\n",
      "Requirement already satisfied: regex in c:\\local\\anaconda3\\lib\\site-packages (from fairseq==0.10.0) (2020.10.15)\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in c:\\local\\anaconda3\\lib\\site-packages (from fairseq==0.10.0) (2.0.0)\n",
      "Requirement already satisfied: torch in c:\\local\\anaconda3\\lib\\site-packages (from fairseq==0.10.0) (1.10.2)\n",
      "Requirement already satisfied: cffi in c:\\local\\anaconda3\\lib\\site-packages (from fairseq==0.10.0) (1.14.3)\n",
      "Requirement already satisfied: hydra-core in c:\\local\\anaconda3\\lib\\site-packages (from fairseq==0.10.0) (1.1.1)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\local\\anaconda3\\lib\\site-packages (from sacrebleu>=1.4.12->fairseq==0.10.0) (0.8.9)\n",
      "Requirement already satisfied: colorama in c:\\local\\anaconda3\\lib\\site-packages (from sacrebleu>=1.4.12->fairseq==0.10.0) (0.4.4)\n",
      "Requirement already satisfied: portalocker in c:\\local\\anaconda3\\lib\\site-packages (from sacrebleu>=1.4.12->fairseq==0.10.0) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\local\\anaconda3\\lib\\site-packages (from torch->fairseq==0.10.0) (4.0.1)\n",
      "Requirement already satisfied: pycparser in c:\\local\\anaconda3\\lib\\site-packages (from cffi->fairseq==0.10.0) (2.20)\n",
      "Requirement already satisfied: omegaconf==2.1.* in c:\\local\\anaconda3\\lib\\site-packages (from hydra-core->fairseq==0.10.0) (2.1.1)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in c:\\local\\anaconda3\\lib\\site-packages (from hydra-core->fairseq==0.10.0) (5.4.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in c:\\local\\anaconda3\\lib\\site-packages (from hydra-core->fairseq==0.10.0) (4.8)\n",
      "Requirement already satisfied: pywin32>=226; platform_system == \"Windows\" in c:\\local\\anaconda3\\lib\\site-packages (from portalocker->sacrebleu>=1.4.12->fairseq==0.10.0) (227)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in c:\\local\\anaconda3\\lib\\site-packages (from omegaconf==2.1.*->hydra-core->fairseq==0.10.0) (5.3.1)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in c:\\local\\anaconda3\\lib\\site-packages (from importlib-resources; python_version < \"3.9\"->hydra-core->fairseq==0.10.0) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fairseq==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in c:\\local\\anaconda3\\lib\\site-packages (from sacremoses) (4.50.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib in c:\\local\\anaconda3\\lib\\site-packages (from sacremoses) (0.17.0)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\local\\anaconda3\\lib\\site-packages (from sacremoses) (1.16.0)\n",
      "Requirement already satisfied, skipping upgrade: click in c:\\local\\anaconda3\\lib\\site-packages (from sacremoses) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: regex in c:\\local\\anaconda3\\lib\\site-packages (from sacremoses) (2020.10.15)\n",
      "Installing collected packages: sacremoses\n",
      "Successfully installed sacremoses-0.0.47\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp38-cp38-win_amd64.whl (1.1 MB)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.96\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: numpy in c:\\local\\anaconda3\\lib\\site-packages (1.22.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade --user numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実践(localで)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3ldTDx2FrjLp"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from sacremoses import MosesTokenizer\n",
    "import sentencepiece as spm\n",
    "from fairseq.models.transformer import TransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5jg6rlaqr9Ax"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-02 15:29:10 | INFO | fairseq.file_utils | loading archive file ./checkpoints/\n",
      "2022-03-02 15:29:10 | INFO | fairseq.file_utils | loading archive file data-bin\n",
      "2022-03-02 15:29:10 | INFO | fairseq.tasks.translation | [en] dictionary: 3888 types\n",
      "2022-03-02 15:29:10 | INFO | fairseq.tasks.translation | [ja] dictionary: 3888 types\n",
      "2022-03-02 15:29:11 | INFO | fairseq.models.fairseq_model | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.999)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=4, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=4, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.6, layernorm_embedding=False, left_pad_source=False, left_pad_target=False, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.002], lr_scheduler='inverse_sqrt', max_epoch=10, max_source_positions=1024, max_target_positions=1024, max_tokens=4000, max_tokens_valid=4000, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=10, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', stop_time_hours=0, target_lang='ja', task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=1e-07, warmup_updates=2000, weight_decay=0.01, zero_sharding='none')\n"
     ]
    }
   ],
   "source": [
    "mt = MosesTokenizer(lang = 'en')\n",
    "sp = spm.SentencePieceProcessor(model_file='bpe.model')\n",
    "ejmodel = TransformerModel.from_pretrained('./checkpoints/', checkpoint_file='checkpoint10.pt', data_name_or_path='data-bin')\n",
    "\n",
    "def preproc_en(x):\n",
    "  x = unicodedata.normalize('NFKC', x)\n",
    "  x = re.sub(mt.AGGRESSIVE_HYPHEN_SPLIT[0], r'\\1 - ', x)\n",
    "  x = mt.tokenize(x, escape = False)\n",
    "  x = ' '.join(x)\n",
    "  x = x.lower()\n",
    "  x = ' '.join(sp.encode(x, out_type = 'str'))\n",
    "  return x\n",
    "\n",
    "def ejtranslate(x):\n",
    "  x = preproc_en(x)\n",
    "  x = ejmodel.translate(x, beam = 5, lenpen = 0.6)\n",
    "  x = ''.join(x.split()).replace('▁', '').strip()\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13965,
     "status": "ok",
     "timestamp": 1645979280613,
     "user": {
      "displayName": "小笠雄也",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3-7lYEXBfIfaYmq_UtMxNULG57MqI8cexF-rY=s64",
      "userId": "11557424356353414933"
     },
     "user_tz": -540
    },
    "id": "GZiI1ffvswHT",
    "outputId": "6d9f11ff-5015-428d-d619-02e88c646895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "英文を入力 > \n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "  x = input('英文を入力 > ')\n",
    "  if not x:\n",
    "    break\n",
    "  x = ejtranslate(x)\n",
    "  print('翻訳結果 > ' + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.models.transformer import TransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-02 15:29:29 | INFO | fairseq.file_utils | loading archive file ./save98_2/\n",
      "2022-03-02 15:29:29 | INFO | fairseq.file_utils | loading archive file data98_2\n",
      "2022-03-02 15:29:30 | INFO | fairseq.tasks.translation | [ja] dictionary: 31144 types\n",
      "2022-03-02 15:29:30 | INFO | fairseq.tasks.translation | [en] dictionary: 29424 types\n",
      "2022-03-02 15:29:30 | INFO | fairseq.models.fairseq_model | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.999)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data98_2', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method='tcp://localhost:14033', distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=False, left_pad_target=False, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.001], lr_scheduler='inverse_sqrt', max_epoch=10, max_source_positions=1024, max_target_positions=1024, max_tokens=8000, max_tokens_valid=8000, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=8, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='save98_1/checkpoint3.pt', save_dir='save98_2', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='ja', stop_time_hours=0, target_lang='en', task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=0, warmup_updates=2000, weight_decay=0.0001, zero_sharding='none')\n"
     ]
    }
   ],
   "source": [
    "jemodel = TransformerModel.from_pretrained('./save98_2/', checkpoint_file='checkpoint10.pt', data_name_or_path='data98_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "import sys\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jetranslate(x):\n",
    "    wakati = MeCab.Tagger('-Owakati')\n",
    "    wakati = ' '.join(wakati.parse(x).split())\n",
    "    x = jemodel.translate(wakati, beam = 5, lenpen = 0.6) \n",
    "    x = re.sub('@@ ?$', '', x)\n",
    "    x = re.sub('@@ ', '', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've been adopted by Dogen.\n"
     ]
    }
   ],
   "source": [
    "text = \"私は、道元です。\"\n",
    "print(jetranslate(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "CJtunXu9-3WE"
   },
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEBサーバ　翻訳機\n",
    "jupyter notebookでプログラム実行後\n",
    "\n",
    "`ngrok http 5000`\n",
    "\n",
    "をpowershellなどで実行すると公開できる\n",
    "https://3668-58-190-38-21.ngrok.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "executionInfo": {
     "elapsed": 239,
     "status": "error",
     "timestamp": 1645980755965,
     "user": {
      "displayName": "小笠雄也",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3-7lYEXBfIfaYmq_UtMxNULG57MqI8cexF-rY=s64",
      "userId": "11557424356353414933"
     },
     "user_tz": -540
    },
    "id": "mWiSyEMu-52i",
    "outputId": "9910c396-13b4-4f85-e55b-1e69a6d826d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-02 15:29:44 | INFO | werkzeug |  * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "2022-03-02 15:29:48 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 15:29:48] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 15:29:48 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 15:29:48] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "2022-03-02 15:31:18 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 15:31:18] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 15:32:11 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 15:32:11] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 15:32:12 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 15:32:12] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "2022-03-02 15:32:17 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 15:32:17] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 15:32:23 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 15:32:23] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 15:32:29 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 15:32:29] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 15:33:51 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 15:33:51] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 15:33:52 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 15:33:52] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "2022-03-02 15:33:53 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 15:33:53] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 15:39:14 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 15:39:14] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 15:39:15 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 15:39:15] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "2022-03-02 15:39:36 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 15:39:36] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 15:39:49 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 15:39:49] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 15:39:49 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 15:39:49] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 15:59:37 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 15:59:37] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 15:59:41 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 15:59:41] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 15:59:45 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 15:59:45] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 16:03:23 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 16:03:23] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 16:03:30 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 16:03:30] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 16:06:25 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 16:06:25] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 16:30:41 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 16:30:41] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 16:40:08 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 16:40:08] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 16:49:55 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 16:49:55] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 16:49:59 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 16:49:59] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 16:50:07 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 16:50:07] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 16:50:15 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 16:50:15] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 16:50:21 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 16:50:21] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 16:50:25 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 16:50:25] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 16:50:35 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 16:50:35] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 16:50:58 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 16:50:58] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 16:51:03 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 16:51:03] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 16:51:11 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 16:51:11] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 16:51:18 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 16:51:18] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 16:51:19 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 16:51:19] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 16:51:34 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 16:51:34] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 16:55:26 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 16:55:26] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 16:55:32 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 16:55:32] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:03:08 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:03:08] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:26:06 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:26:06] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:26:10 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:26:10] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:37:41 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:37:41] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:55:47 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:55:47] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:55:47 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:55:47] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:55:47 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:55:47] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "2022-03-02 17:55:48 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:55:48] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "2022-03-02 17:55:50 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:55:50] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:55:52 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:55:52] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:55:53 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:55:53] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "2022-03-02 17:55:58 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:55:58] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:56:05 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:56:05] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:56:06 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:56:06] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:56:07 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:56:07] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:56:08 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:56:08] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "2022-03-02 17:56:14 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:56:14] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:56:15 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:56:15] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:56:22 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:56:22] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:56:31 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:56:31] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:56:31 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:56:31] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:56:32 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:56:32] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:56:35 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:56:35] \"GET / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:56:43 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:56:43] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:56:55 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:56:55] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:56:58 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:56:58] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:57:19 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:57:19] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:57:26 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:57:26] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:57:32 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:57:32] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:57:33 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:57:33] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:57:42 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:57:42] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:57:45 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:57:45] \"POST / HTTP/1.1\" 200 -\n",
      "2022-03-02 17:59:56 | INFO | werkzeug | 127.0.0.1 - - [02/Mar/2022 17:59:56] \"POST / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\", methods=[\"GET\"])\n",
    "def get():\n",
    "    return render_template(\"index.html\", \\\n",
    "        title = \"日⇔英翻訳機\", \\\n",
    "        message = \"Please enter the text you want to translate here.(翻訳したい文を入れてください)\",\\\n",
    "        ejmessage = \"\",\\\n",
    "        jemessage = \"\")\n",
    "\n",
    "@app.route(\"/\", methods=[\"POST\"])\n",
    "def post():\n",
    "    ejtext = request.form[\"ejname\"]\n",
    "    #if re.compile(\\s*).search(ejtext):\n",
    "    if ejtext ==\"\":\n",
    "     ejoutput =\"\"\n",
    "    else:\n",
    "     ejoutput = ejtranslate(ejtext)\n",
    "    jetext = request.form[\"jename\"]\n",
    "    if jetext ==\"\":\n",
    "     jeoutput =\"\"\n",
    "    else:    \n",
    "     jeoutput = jetranslate(jetext)\n",
    "    return render_template(\"index.html\",\\\n",
    "        title = \"日⇔英翻訳機(出力結果)\",\\\n",
    "        message = \"翻訳完了\",\\\n",
    "        ejmessage = \"英→日結果:　　\"+ejtext+\"　　→　　\"+ejoutput ,\\\n",
    "        jemessage = \"日→英結果:　　\"+jetext+\"　　→　　\"+jeoutput)\n",
    "        \n",
    "\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V3TCZakJGWnc",
    "outputId": "8f250005-97d7-4e82-a156-c1fbcc07b92a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-28 12:18:42 | INFO | werkzeug |  * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "2022-02-28 12:18:44 | ERROR | __main__ | Exception on / [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\local\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\local\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\local\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\local\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\local\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\local\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-13-bcd5052f4311>\", line 5, in get\n",
      "    return render_template(\"index.html\", \\\n",
      "  File \"C:\\local\\Anaconda3\\lib\\site-packages\\flask\\templating.py\", line 138, in render_template\n",
      "    ctx.app.jinja_env.get_or_select_template(template_name_or_list),\n",
      "  File \"C:\\local\\Anaconda3\\lib\\site-packages\\jinja2\\environment.py\", line 930, in get_or_select_template\n",
      "    return self.get_template(template_name_or_list, parent, globals)\n",
      "  File \"C:\\local\\Anaconda3\\lib\\site-packages\\jinja2\\environment.py\", line 883, in get_template\n",
      "    return self._load_template(name, self.make_globals(globals))\n",
      "  File \"C:\\local\\Anaconda3\\lib\\site-packages\\jinja2\\environment.py\", line 857, in _load_template\n",
      "    template = self.loader.load(self, name, globals)\n",
      "  File \"C:\\local\\Anaconda3\\lib\\site-packages\\jinja2\\loaders.py\", line 115, in load\n",
      "    source, filename, uptodate = self.get_source(environment, name)\n",
      "  File \"C:\\local\\Anaconda3\\lib\\site-packages\\flask\\templating.py\", line 60, in get_source\n",
      "    return self._get_source_fast(environment, template)\n",
      "  File \"C:\\local\\Anaconda3\\lib\\site-packages\\flask\\templating.py\", line 89, in _get_source_fast\n",
      "    raise TemplateNotFound(template)\n",
      "jinja2.exceptions.TemplateNotFound: index.html\n",
      "2022-02-28 12:18:44 | INFO | werkzeug | 127.0.0.1 - - [28/Feb/2022 12:18:44] \"\u001b[35m\u001b[1mGET / HTTP/1.1\u001b[0m\" 500 -\n",
      "2022-02-28 12:19:01 | INFO | werkzeug | 127.0.0.1 - - [28/Feb/2022 12:19:01] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def hello():\n",
    "  return 'Hello World!'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  app.run()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "light_enja2.ipynb",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
