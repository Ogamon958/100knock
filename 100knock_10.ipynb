{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KFTT http://www.phontron.com/kftt/index-ja.html#data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 90 データの準備\n",
    "#### 機械翻訳のデータセットをダウンロードせよ．訓練データ，開発データ，評価データを整形し，必要に応じてトークン化などの前処理を行うこと．ただし，この段階ではトークンの単位として形態素（日本語）および単語（英語）を採用せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-14 01:17:20--  http://www.phontron.com/kftt/download/kftt-data-1.0.tar.gz\n",
      "Resolving www.phontron.com (www.phontron.com)... 208.113.196.149\n",
      "Connecting to www.phontron.com (www.phontron.com)|208.113.196.149|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 99246893 (95M) [application/gzip]\n",
      "Saving to: ‘kftt-data-1.0.tar.gz’\n",
      "\n",
      "kftt-data-1.0.tar.g 100%[===================>]  94.65M  16.6MB/s    in 6.8s    \n",
      "\n",
      "2022-02-14 01:17:28 (13.8 MB/s) - ‘kftt-data-1.0.tar.gz’ saved [99246893/99246893]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.phontron.com/kftt/download/kftt-data-1.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kftt-data-1.0/\n",
      "kftt-data-1.0/data/\n",
      "kftt-data-1.0/data/orig/\n",
      "kftt-data-1.0/data/orig/kyoto-tune.en\n",
      "kftt-data-1.0/data/orig/kyoto-dev.ja\n",
      "kftt-data-1.0/data/orig/kyoto-dev.en\n",
      "kftt-data-1.0/data/orig/kyoto-train.en\n",
      "kftt-data-1.0/data/orig/kyoto-tune.ja\n",
      "kftt-data-1.0/data/orig/kyoto-train.ja\n",
      "kftt-data-1.0/data/orig/kyoto-test.ja\n",
      "kftt-data-1.0/data/orig/kyoto-test.en\n",
      "kftt-data-1.0/data/tok/\n",
      "kftt-data-1.0/data/tok/kyoto-tune.en\n",
      "kftt-data-1.0/data/tok/kyoto-dev.ja\n",
      "kftt-data-1.0/data/tok/kyoto-train.cln.en\n",
      "kftt-data-1.0/data/tok/kyoto-dev.en\n",
      "kftt-data-1.0/data/tok/kyoto-train.en\n",
      "kftt-data-1.0/data/tok/kyoto-tune.ja\n",
      "kftt-data-1.0/data/tok/kyoto-train.cln.ja\n",
      "kftt-data-1.0/data/tok/kyoto-train.ja\n",
      "kftt-data-1.0/data/tok/kyoto-test.ja\n",
      "kftt-data-1.0/data/tok/kyoto-test.en\n",
      "kftt-data-1.0/README.txt\n"
     ]
    }
   ],
   "source": [
    "!tar zxvf kftt-data-1.0.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ginzaについて https://megagonlabs.github.io/ginza/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Collecting ginza\n",
      "  Downloading ginza-5.1.0.tar.gz (25 kB)\n",
      "Collecting spacy<3.3.0,>=3.2.0\n",
      "  Downloading spacy-3.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.2 MB 8.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting plac>=1.3.3\n",
      "  Downloading plac-1.3.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting SudachiPy<0.7.0,>=0.5.4\n",
      "  Downloading SudachiPy-0.6.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting SudachiDict-core>=20210802\n",
      "  Downloading SudachiDict-core-20211220.tar.gz (9.1 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 3.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->ginza) (49.6.0.post20210108)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "\u001b[K     |████████████████████████████████| 181 kB 68.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.9 MB 66.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->ginza) (2.11.3)\n",
      "Collecting thinc<8.1.0,>=8.0.12\n",
      "  Downloading thinc-8.0.13-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 78.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->ginza) (1.19.5)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp38-cp38-manylinux2014_x86_64.whl (13.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.7 MB 80.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.6-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->ginza) (2.25.1)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
      "\u001b[K     |████████████████████████████████| 454 kB 79.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.9.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->ginza) (4.60.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->ginza) (20.9)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.6-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[K     |████████████████████████████████| 130 kB 68.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->ginza) (2.4.7)\n",
      "Collecting smart-open<6.0.0,>=5.0.0\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 19.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->ginza) (3.7.4.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->ginza) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->ginza) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->ginza) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->ginza) (2.10)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->ginza) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.8/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->ginza) (1.1.1)\n",
      "Building wheels for collected packages: ginza, SudachiDict-core\n",
      "  Building wheel for ginza (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ginza: filename=ginza-5.1.0-py3-none-any.whl size=20090 sha256=f83fcf918ed58d14031b13507a3a9a5de5f8ecf4dd5631fa143f96d18ee11c8b\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/32/8f/d3/896c669c92aa43d2d3f094681c39c0c2c376f07aa5c654007f\n",
      "  Building wheel for SudachiDict-core (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for SudachiDict-core: filename=SudachiDict_core-20211220-py3-none-any.whl size=71565332 sha256=a3c828461308199edbdea65c0b823e024106899d3676b19aeaf68da7eddbe65b\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/01/b5/b9/a18f424b45892ca02ca5762b844ad49be1f638e913e8e625fa\n",
      "Successfully built ginza SudachiDict-core\n",
      "Installing collected packages: murmurhash, cymem, catalogue, wasabi, typer, srsly, smart-open, pydantic, preshed, blis, thinc, SudachiPy, spacy-loggers, spacy-legacy, pathy, langcodes, SudachiDict-core, spacy, plac, ginza\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Successfully installed SudachiDict-core-20211220 SudachiPy-0.6.3 blis-0.7.5 catalogue-2.0.6 cymem-2.0.6 ginza-5.1.0 langcodes-3.3.0 murmurhash-1.0.6 pathy-0.6.1 plac-1.3.4 preshed-3.0.6 pydantic-1.8.2 smart-open-5.2.1 spacy-3.2.2 spacy-legacy-3.0.8 spacy-loggers-1.0.1 srsly-2.4.2 thinc-8.0.13 typer-0.4.0 wasabi-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ginza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat kftt-data-1.0/data/orig/kyoto-train.ja | sed 's/\\s+/ /g' | ginzame > train.ginza.ja\n",
    "!cat kftt-data-1.0/data/orig/kyoto-dev.ja | sed 's/\\s+/ /g' | ginzame > dev.ginza.ja\n",
    "!cat kftt-data-1.0/data/orig/kyoto-test.ja | sed 's/\\s+/ /g' | ginzame > test.ginza.ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for src, dst in [\n",
    "    ('train.ginza.ja', 'train.ja'),\n",
    "    ('dev.ginza.ja', 'dev.ja'),\n",
    "    ('test.ginza.ja', 'test.ja'),\n",
    "]:\n",
    "    with open(src) as f:\n",
    "        lst = []\n",
    "        tmp = []\n",
    "        for x in f:\n",
    "            x = x.strip()\n",
    "            if x == 'EOS':\n",
    "                lst.append(' '.join(tmp))\n",
    "                tmp = []\n",
    "            elif x != '':\n",
    "                tmp.append(x.split('\\t')[0])\n",
    "    with open(dst, 'w') as f:\n",
    "        for line in lst:\n",
    "            print(line, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "雪舟 （ せっ しゅう 、 1420 年 （ 応永 27 年 ） - 1506 年 （ 永正 3 年 ） ） は 号 で 、 15 世紀 後半 室町 時代 に 活躍 し た 水墨 画家 ・ 禅僧 で 、 画聖 と も 称え られる 。\n",
      "日本 の 水墨 画 を 一変 さ せ た 。\n",
      "諱 は 「 等楊（とうよう） 」 、 もしくは 「 拙 宗 （ せっ しゅう ） 」 と 号し た 。\n",
      "備中 国 に 生まれ 、 京都 ・ 相国 寺 に 入っ て から 周防 国 に 移る 。\n",
      "その 後 遣明 使 に 随行 し て 中国 （ 明 ） に 渡っ て 中国 の 水墨 画 を 学ん だ 。\n",
      "作品 は 数多く 、 中国 風 の 山水 画 だけ で なく 人物 画 や 花鳥 画 も よく し た 。\n",
      "大胆 な 構図 と 力強い 筆線 は 非常 に 個性 的 な 画風 を 作り 出し て いる 。\n",
      "現存 する 作品 の うち 6 点 が 国宝 に 指定 さ れ て おり 、 日本 の 画家 の なか で も 別格 の 評価 を 受け て いる と いえる 。\n",
      "この ため 、 花鳥 図 屏風 など に 「 伝 雪舟 筆 」 さ れる 作品 は 大変 多い 。\n",
      "真筆 で ある か 専門 家 の 間 で も 意見 の 分かれる もの も 多々 ある 。\n"
     ]
    }
   ],
   "source": [
    "!head train.ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-20 04:12:26.325377: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.9 MB 311 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /opt/conda/lib/python3.8/site-packages (from en-core-web-sm==3.2.0) (3.2.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.19.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (20.9)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (49.6.0.post20210108)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.25.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.60.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.7.4.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2020.12.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.8/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Successfully installed en-core-web-sm-3.2.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "for src, dst in [\n",
    "    ('kftt-data-1.0/data/orig/kyoto-train.en', 'train.en'),\n",
    "    ('kftt-data-1.0/data/orig/kyoto-dev.en', 'dev.en'),\n",
    "    ('kftt-data-1.0/data/orig/kyoto-test.en', 'test.en'),\n",
    "]:\n",
    "    with open(src) as f, open(dst, 'w') as g:\n",
    "        for x in f:\n",
    "            x = x.strip()\n",
    "            x = re.sub(r'\\s+', ' ', x)\n",
    "            x = nlp.make_doc(x)\n",
    "            x = ' '.join([doc.text for doc in x])\n",
    "            print(x, file=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known as Sesshu ( 1420 - 1506 ) , he was an ink painter and Zen monk active in the Muromachi period in the latter half of the 15th century , and was called a master painter .\n",
      "He revolutionized the Japanese ink painting .\n",
      "He was given the posthumous name \" Toyo \" or \" Sesshu ( 拙宗 ) . \"\n",
      "Born in Bicchu Province , he moved to Suo Province after entering SShokoku - ji Temple in Kyoto .\n",
      "Later he accompanied a mission to Ming Dynasty China and learned Chinese ink painting .\n",
      "His works were many , including not only Chinese - style landscape paintings , but also portraits and pictures of flowers and birds .\n",
      "His bold compositions and strong brush strokes constituted an extremely distinctive style .\n",
      "6 of his extant works are designated national treasures . Indeed , he is considered to be extraordinary among Japanese painters .\n",
      "For this reason , there are a great many artworks that are attributed to him , such as folding screens with pictures of flowers and that birds are painted on them .\n",
      "There are many works that even experts can not agree if they are really his work or not .\n"
     ]
    }
   ],
   "source": [
    "!head train.en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 91 機械翻訳モデルの訓練 \n",
    "#### 90で準備したデータを用いて，ニューラル機械翻訳のモデルを学習せよ（ニューラルネットワークのモデルはTransformerやLSTMなど適当に選んでよい）．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "fairseqを用いる.  \n",
    "https://qiita.com/keita_M/items/3a7401ef48df3ec92b6f fairseqの使い方  \n",
    "command https://fairseq.readthedocs.io/en/latest/command_line_tools.html  \n",
    "https://torch.classcat.com/category/fairseq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Collecting fairseq==0.10.2\n",
      "  Downloading fairseq-0.10.2-cp38-cp38-manylinux1_x86_64.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 6.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex\n",
      "  Downloading regex-2022.1.18-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\n",
      "\u001b[K     |████████████████████████████████| 764 kB 56.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cffi in /opt/conda/lib/python3.8/site-packages (from fairseq==0.10.2) (1.14.5)\n",
      "Collecting sacrebleu>=1.4.12\n",
      "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
      "\u001b[K     |████████████████████████████████| 90 kB 25.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cython in /opt/conda/lib/python3.8/site-packages (from fairseq==0.10.2) (0.29.23)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from fairseq==0.10.2) (1.8.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from fairseq==0.10.2) (4.60.0)\n",
      "Collecting hydra-core\n",
      "  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
      "\u001b[K     |████████████████████████████████| 145 kB 65.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from fairseq==0.10.2) (1.19.5)\n",
      "Collecting dataclasses\n",
      "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Collecting tabulate>=0.8.9\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi->fairseq==0.10.2) (2.20)\n",
      "Collecting omegaconf==2.1.*\n",
      "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
      "\u001b[K     |████████████████████████████████| 74 kB 9.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting antlr4-python3-runtime==4.8\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 39.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-resources\n",
      "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /opt/conda/lib/python3.8/site-packages (from omegaconf==2.1.*->hydra-core->fairseq==0.10.2) (5.4.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources->hydra-core->fairseq==0.10.2) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch->fairseq==0.10.2) (3.7.4.3)\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=46aac8d333e46c5fef11fbfe5524161fd616de719288ad2e9d4452069640fbcb\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/c8/d0/ab/d43c02eaddc5b9004db86950802442ad9a26f279c619e28da0\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, tabulate, regex, portalocker, omegaconf, importlib-resources, colorama, sacrebleu, hydra-core, dataclasses, fairseq\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Successfully installed antlr4-python3-runtime-4.8 colorama-0.4.4 dataclasses-0.6 fairseq-0.10.2 hydra-core-1.1.1 importlib-resources-5.4.0 omegaconf-2.1.1 portalocker-2.4.0 regex-2022.1.18 sacrebleu-2.0.0 tabulate-0.8.9\n"
     ]
    }
   ],
   "source": [
    "!pip install fairseq==0.10.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### gitからインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'fairseq'...\n",
      "remote: Enumerating objects: 30878, done.\u001b[K\n",
      "remote: Counting objects: 100% (510/510), done.\u001b[K\n",
      "remote: Compressing objects: 100% (307/307), done.\u001b[K\n",
      "remote: Total 30878 (delta 217), reused 399 (delta 196), pack-reused 30368\u001b[K\n",
      "Receiving objects: 100% (30878/30878), 21.18 MiB | 14.73 MiB/s, done.\n",
      "Resolving deltas: 100% (22912/22912), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/pytorch/fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/code/10/fairseq\n"
     ]
    }
   ],
   "source": [
    "cd fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Obtaining file:///home/jovyan/code/10/fairseq\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: hydra-core<1.1,>=1.0.7 in /opt/conda/lib/python3.8/site-packages (from fairseq==1.0.0a0+5f2515e) (1.0.7)\n",
      "Requirement already satisfied: cffi in /opt/conda/lib/python3.8/site-packages (from fairseq==1.0.0a0+5f2515e) (1.14.5)\n",
      "Requirement already satisfied: cython in /opt/conda/lib/python3.8/site-packages (from fairseq==1.0.0a0+5f2515e) (0.29.23)\n",
      "Requirement already satisfied: torchaudio>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from fairseq==1.0.0a0+5f2515e) (0.8.1)\n",
      "Requirement already satisfied: omegaconf<2.1 in /opt/conda/lib/python3.8/site-packages (from fairseq==1.0.0a0+5f2515e) (2.0.6)\n",
      "Requirement already satisfied: bitarray in /opt/conda/lib/python3.8/site-packages (from fairseq==1.0.0a0+5f2515e) (2.3.6)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from fairseq==1.0.0a0+5f2515e) (1.19.5)\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in /opt/conda/lib/python3.8/site-packages (from fairseq==1.0.0a0+5f2515e) (2.0.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from fairseq==1.0.0a0+5f2515e) (4.60.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from fairseq==1.0.0a0+5f2515e) (1.8.1)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.8/site-packages (from fairseq==1.0.0a0+5f2515e) (2022.1.18)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.8/site-packages (from hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+5f2515e) (5.4.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /opt/conda/lib/python3.8/site-packages (from hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+5f2515e) (4.8)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /opt/conda/lib/python3.8/site-packages (from omegaconf<2.1->fairseq==1.0.0a0+5f2515e) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from omegaconf<2.1->fairseq==1.0.0a0+5f2515e) (3.7.4.3)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.8/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+5f2515e) (2.3.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.8/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+5f2515e) (0.8.9)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.8/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+5f2515e) (0.4.4)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi->fairseq==1.0.0a0+5f2515e) (2.20)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+5f2515e) (3.4.1)\n",
      "Installing collected packages: fairseq\n",
      "  Attempting uninstall: fairseq\n",
      "    Found existing installation: fairseq 0.10.2\n",
      "    Uninstalling fairseq-0.10.2:\n",
      "      Successfully uninstalled fairseq-0.10.2\n",
      "  Running setup.py develop for fairseq\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Successfully installed fairseq-1.0.0a0+5f2515e\n"
     ]
    }
   ],
   "source": [
    "!pip install --editable ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/code/10\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ここまでインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-14 05:44:16 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data91', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=8, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='ja', srcdict=None, target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=5, thresholdtgt=5, tokenizer=None, tpu=False, trainpref='train', user_dir=None, validpref='dev', workers=30)\n",
      "2022-02-14 05:44:25 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 53928 types\n",
      "2022-02-14 05:44:34 | INFO | fairseq_cli.preprocess | [ja] train.ja: 440288 sents, 11550262 tokens, 1.24% replaced by <unk>\n",
      "2022-02-14 05:44:34 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 53928 types\n",
      "2022-02-14 05:44:35 | INFO | fairseq_cli.preprocess | [ja] dev.ja: 1166 sents, 26468 tokens, 1.24% replaced by <unk>\n",
      "2022-02-14 05:44:35 | INFO | fairseq_cli.preprocess | [en] Dictionary: 55472 types\n",
      "2022-02-14 05:44:43 | INFO | fairseq_cli.preprocess | [en] train.en: 440288 sents, 12321279 tokens, 1.56% replaced by <unk>\n",
      "2022-02-14 05:44:43 | INFO | fairseq_cli.preprocess | [en] Dictionary: 55472 types\n",
      "2022-02-14 05:44:44 | INFO | fairseq_cli.preprocess | [en] dev.en: 1166 sents, 26101 tokens, 2.83% replaced by <unk>\n",
      "2022-02-14 05:44:44 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data91\n"
     ]
    }
   ],
   "source": [
    "!fairseq-preprocess -s ja -t en \\\n",
    "    --trainpref train \\\n",
    "    --validpref dev \\\n",
    "    --destdir data91  \\\n",
    "    --model-parallel-size 8 \\\n",
    "    --thresholdsrc 5 \\\n",
    "    --thresholdtgt 5 \\\n",
    "    --workers 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 14 05:45:02 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.82.00    Driver Version: 470.82.00    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA TITAN X ...  On   | 00000000:04:00.0 Off |                  N/A |\n",
      "| 23%   22C    P8    11W / 250W |      6MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA TITAN X ...  On   | 00000000:05:00.0 Off |                  N/A |\n",
      "| 23%   25C    P8    10W / 250W |      6MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA TITAN X ...  On   | 00000000:08:00.0 Off |                  N/A |\n",
      "| 23%   22C    P8     7W / 250W |      6MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA TITAN X ...  On   | 00000000:09:00.0 Off |                  N/A |\n",
      "| 23%   24C    P8     8W / 250W |      6MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA TITAN X ...  On   | 00000000:84:00.0 Off |                  N/A |\n",
      "| 23%   26C    P8     8W / 250W |      6MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA TITAN X ...  On   | 00000000:85:00.0 Off |                  N/A |\n",
      "| 23%   24C    P8     8W / 250W |      6MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA TITAN X ...  On   | 00000000:88:00.0 Off |                  N/A |\n",
      "| 23%   23C    P8     8W / 250W |      6MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA TITAN X ...  On   | 00000000:89:00.0 Off |                  N/A |\n",
      "| 23%   24C    P8     8W / 250W |      6MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: pathspec 'fairseq/model_parallel/megatron' did not match any file(s) known to git\n"
     ]
    }
   ],
   "source": [
    "!git submodule update --init fairseq/model_parallel/megatron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "epoch 002:   0%|                                        | 0/228 [00:00<?, ?it/s]/opt/conda/lib/python3.8/site-packages/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
      "  warnings.warn(\n",
      "epoch 002: 100%|▉| 227/228 [02:57<00:00,  1.31it/s, loss=8.945, nll_loss=7.917, \n",
      "epoch 002 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.15s/it]\u001b[A\n",
      "epoch 003: 100%|▉| 227/228 [02:54<00:00,  1.32it/s, loss=8.015, nll_loss=6.84, p\u001b[A\n",
      "epoch 003 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.13s/it]\u001b[A\n",
      "epoch 004: 100%|▉| 227/228 [02:54<00:00,  1.31it/s, loss=7.106, nll_loss=5.775, \u001b[A\n",
      "epoch 004 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      "epoch 005: 100%|▉| 227/228 [02:54<00:00,  1.31it/s, loss=6.528, nll_loss=5.1, pp\u001b[A\n",
      "epoch 005 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.08s/it]\u001b[A\n",
      "epoch 006: 100%|▉| 227/228 [02:54<00:00,  1.31it/s, loss=6.076, nll_loss=4.572, \u001b[A\n",
      "epoch 006 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 006 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.08s/it]\u001b[A\n",
      "epoch 007: 100%|▉| 227/228 [02:55<00:00,  1.30it/s, loss=5.609, nll_loss=4.03, p\u001b[A\n",
      "epoch 007 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 007 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.14s/it]\u001b[A\n",
      "epoch 008: 100%|▉| 227/228 [02:54<00:00,  1.29it/s, loss=5.205, nll_loss=3.558, \u001b[A\n",
      "epoch 008 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 008 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.09s/it]\u001b[A\n",
      "epoch 009: 100%|▉| 227/228 [02:54<00:00,  1.32it/s, loss=4.974, nll_loss=3.292, \u001b[A\n",
      "epoch 009 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 009 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.11s/it]\u001b[A\n",
      "epoch 010: 100%|▉| 227/228 [02:55<00:00,  1.30it/s, loss=4.802, nll_loss=3.096, \u001b[A\n",
      "epoch 010 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 010 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.09s/it]\u001b[A\n",
      "/opt/conda/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 144 leaked semaphore objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    }
   ],
   "source": [
    "!fairseq-train data91 \\\n",
    "    --memory-efficient-fp16 \\\n",
    "    --save-dir save91 \\\n",
    "    --max-epoch 10 \\\n",
    "    --arch transformer --share-decoder-input-output-embed \\\n",
    "    --optimizer adam --clip-norm 1.0 \\\n",
    "    --lr 1e-3 --lr-scheduler inverse_sqrt --warmup-updates 2000 \\\n",
    "    --update-freq 1 \\\n",
    "    --dropout 0.2 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 8000 > 91.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 92 機械翻訳モデルの適用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fairseq-interactive --path save91/checkpoint10.pt data91 < test.ja | grep '^H' | cut -f3 > 92.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 93 BLEUスコアの計測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(ignore_case=False, order=4, ref='test.en', sacrebleu=False, sentence_bleu=False, sys='92.out')\n",
      "BLEU4 = 22.08, 52.9/27.2/16.1/10.3 (BP=1.000, ratio=1.026, syslen=28367, reflen=27636)\n"
     ]
    }
   ],
   "source": [
    "!fairseq-score --sys 92.out --ref test.en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 94 ビーム探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "for N in `seq 1 20` ; do\n",
    "    fairseq-interactive --path save91/checkpoint10.pt --beam $N data91 < test.ja | grep '^H' | cut -f3 > 94.$N.out\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "for N in `seq 1 20` ; do\n",
    "    fairseq-score --sys 94.$N.out --ref test.en > 94.$N.score\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_score(filename):\n",
    "    with open(filename) as f:\n",
    "        x = f.readlines()[1]\n",
    "        x = re.search(r'(?<=BLEU4 = )\\d*\\.\\d*(?=,)', x)\n",
    "        return float(x.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = range(1, 21)\n",
    "ys = [read_score(f'94.{x}.score') for x in xs]\n",
    "plt.plot(xs, ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 95. サブワード化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 6.1 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Successfully installed sentencepiece-0.1.96\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Collecting subword-nmt\n",
      "  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: mock in /opt/conda/lib/python3.8/site-packages (from subword-nmt) (4.0.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from subword-nmt) (4.60.0)\n",
      "Installing collected packages: subword-nmt\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Successfully installed subword-nmt-0.3.8\n"
     ]
    }
   ],
   "source": [
    "!pip install subword-nmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.Train('--input=kftt-data-1.0/data/orig/kyoto-train.ja --model_prefix=kyoto_ja --vocab_size=16000 --character_coverage=1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load('kyoto_ja.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for src, dst in [\n",
    "    ('kftt-data-1.0/data/orig/kyoto-train.ja', 'train.sub.ja'),\n",
    "    ('kftt-data-1.0/data/orig/kyoto-dev.ja', 'dev.sub.ja'),\n",
    "    ('kftt-data-1.0/data/orig/kyoto-test.ja', 'test.sub.ja'),\n",
    "]:\n",
    "    with open(src) as f, open(dst, 'w') as g:\n",
    "        for x in f:\n",
    "            x = x.strip()\n",
    "            x = re.sub(r'\\s+', ' ', x)\n",
    "            x = sp.encode_as_pieces(x)\n",
    "            x = ' '.join(x)\n",
    "            print(x, file=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁ 雪 舟 ( せ っ しゅう 、 14 20 年 ( 応永 27 年 )- 150 6 年 ( 永正 3 年 ) ) は 号 で 、 15 世紀後半 室町時代に 活躍した 水墨画 家 ・ 禅僧 で 、 画 聖 とも 称え られる 。\n",
      "▁日本の 水墨画 を 一 変 させた 。\n",
      "▁諱は 「 等 楊 ( とう よう ) 」 、 もしくは 「 拙 宗 ( せ っ しゅう ) 」 と号した 。\n",
      "▁ 備中国 に 生まれ 、 京都 ・ 相国寺 に入って から 周防国 に移る 。\n",
      "▁その後 遣 明 使 に 随行 して 中国 ( 明 ) に渡って 中国の 水墨画 を学んだ 。\n",
      "▁ 作品 は 数多く 、 中国 風の 山 水 画 だけでなく 人物 画 や 花鳥 画 も よく した 。\n",
      "▁大 胆 な 構図 と 力 強い 筆 線 は非常に 個 性 的な 画 風 を作り 出している 。\n",
      "▁ 現存する 作品 のうち 6 点 が 国宝 に指定され ており 、 日本の 画家 のなかで も 別 格 の 評価 を受けている といえる 。\n",
      "▁このため 、 花鳥 図屏風 などに 「 伝 雪 舟 筆 」 される 作品 は 大変 多い 。\n",
      "▁ 真 筆 である か 専門 家 の間で も 意見 の 分かれ るもの も 多 々 ある 。\n"
     ]
    }
   ],
   "source": [
    "!head train.sub.ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|####################################| 16000/16000 [01:01<00:00, 258.79it/s]\n"
     ]
    }
   ],
   "source": [
    "!subword-nmt learn-bpe -s 16000 < kftt-data-1.0/data/orig/kyoto-train.en > kyoto_en.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!subword-nmt apply-bpe -c kyoto_en.codes < kftt-data-1.0/data/orig/kyoto-train.en > train.sub.en\n",
    "!subword-nmt apply-bpe -c kyoto_en.codes < kftt-data-1.0/data/orig/kyoto-dev.en > dev.sub.en\n",
    "!subword-nmt apply-bpe -c kyoto_en.codes < kftt-data-1.0/data/orig/kyoto-test.en > test.sub.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K@@ n@@ own as Ses@@ shu (14@@ 20 - 150@@ 6@@ ), he was an ink painter and Zen monk active in the Muromachi period in the latter half of the 15th century, and was called a master pain@@ ter.\n",
      "He revol@@ ut@@ ion@@ ized the Japanese ink paint@@ ing.\n",
      "He was given the posthumous name \"@@ Toyo@@ \" or \"S@@ es@@ shu (@@ 拙@@ 宗@@ ).\"\n",
      "Born in Bicchu Province, he moved to Suo Province after entering S@@ Shokoku-ji Temple in Kyoto.\n",
      "Later he accompanied a mission to Ming Dynasty China and learned Chinese ink paint@@ ing.\n",
      "His works were man@@ y, including not only Chinese-style landscape paintings, but also portraits and pictures of flowers and bird@@ s.\n",
      "His b@@ old compos@@ itions and strong brush st@@ rok@@ es const@@ ituted an extremely distinctive style.\n",
      "6 of his ext@@ ant works are designated national treasu@@ res. In@@ de@@ ed, he is considered to be extraordinary among Japanese pain@@ ters.\n",
      "For this reason, there are a great many art@@ works that are attributed to him, such as folding scre@@ ens with pictures of flowers and that birds are painted on them.\n",
      "There are many works that even experts cannot ag@@ ree if they are really his work or not.\n"
     ]
    }
   ],
   "source": [
    "!head train.sub.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-20 04:37:58 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data95', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=8, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='ja', srcdict=None, target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='train.sub', user_dir=None, validpref='dev.sub', workers=30)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/fairseq-preprocess\", line 8, in <module>\n",
      "    sys.exit(cli_main())\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq_cli/preprocess.py\", line 394, in cli_main\n",
      "    main(args)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq_cli/preprocess.py\", line 74, in main\n",
      "    raise FileExistsError(dict_path(args.source_lang))\n",
      "FileExistsError: data95/dict.ja.txt\n"
     ]
    }
   ],
   "source": [
    "!fairseq-preprocess -s ja -t en \\\n",
    "    --trainpref train.sub \\\n",
    "    --validpref dev.sub \\\n",
    "    --model-parallel-size 8 \\\n",
    "    --destdir data95  \\\n",
    "    --workers 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "epoch 001:   0%|                                        | 0/235 [00:00<?, ?it/s]/opt/conda/lib/python3.8/site-packages/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/fairseq/utils.py:341: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
      "  warnings.warn(\n",
      "epoch 001: 100%|▉| 234/235 [02:24<00:00,  1.66it/s, loss=11.596, nll_loss=11.16,\n",
      "epoch 001 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n",
      "epoch 002: 100%|▉| 234/235 [02:21<00:00,  1.67it/s, loss=10.216, nll_loss=9.545,\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.94s/it]\u001b[A\n",
      "epoch 003: 100%|▉| 234/235 [02:22<00:00,  1.65it/s, loss=8.674, nll_loss=7.729, \u001b[A\n",
      "epoch 003 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n",
      "epoch 004: 100%|▉| 234/235 [02:22<00:00,  1.67it/s, loss=8, nll_loss=6.938, ppl=\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.02s/it]\u001b[A\n",
      "epoch 005: 100%|▉| 234/235 [02:22<00:00,  1.67it/s, loss=7.452, nll_loss=6.299, \u001b[A\n",
      "epoch 005 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  2.00s/it]\u001b[A\n",
      "epoch 006: 100%|▉| 234/235 [02:22<00:00,  1.65it/s, loss=6.721, nll_loss=5.452, \u001b[A\n",
      "epoch 006 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 006 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n",
      "epoch 007: 100%|▉| 234/235 [02:21<00:00,  1.67it/s, loss=6.303, nll_loss=4.969, \u001b[A\n",
      "epoch 007 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 007 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.01s/it]\u001b[A\n",
      "epoch 008: 100%|▉| 234/235 [02:22<00:00,  1.64it/s, loss=5.92, nll_loss=4.528, p\u001b[A\n",
      "epoch 008 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 008 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.93s/it]\u001b[A\n",
      "epoch 009: 100%|▉| 234/235 [02:21<00:00,  1.67it/s, loss=5.501, nll_loss=4.046, \u001b[A\n",
      "epoch 009 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 009 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n",
      "epoch 010: 100%|▉| 234/235 [02:21<00:00,  1.67it/s, loss=5.285, nll_loss=3.799, \u001b[A\n",
      "epoch 010 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 010 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n",
      "/opt/conda/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 160 leaked semaphore objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    }
   ],
   "source": [
    "!fairseq-train data95 \\\n",
    "    --memory-efficient-fp16 \\\n",
    "    --save-dir save95 \\\n",
    "    --max-epoch 10 \\\n",
    "    --arch transformer --share-decoder-input-output-embed \\\n",
    "    --optimizer adam --clip-norm 1.0 \\\n",
    "    --lr 1e-3 --lr-scheduler inverse_sqrt --warmup-updates 2000 \\\n",
    "    --update-freq 1 \\\n",
    "    --dropout 0.2 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 8000 > 95.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fairseq-interactive --path save95/checkpoint10.pt data95 < test.sub.ja | grep '^H' | cut -f3 | sed -r 's/(@@ )|(@@ ?$)//g' > 95.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenize(src, dst):\n",
    "    with open(src) as f, open(dst, 'w') as g:\n",
    "        for x in f:\n",
    "            x = x.strip()\n",
    "            x = ' '.join([doc.text for doc in nlp(x)])\n",
    "            print(x, file=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tokenize('95.out', '95.out.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(ignore_case=False, order=4, ref='test.en', sacrebleu=False, sentence_bleu=False, sys='95.out.spacy')\n",
      "BLEU4 = 18.95, 48.9/23.7/13.5/8.3 (BP=1.000, ratio=1.070, syslen=29576, reflen=27636)\n"
     ]
    }
   ],
   "source": [
    "!fairseq-score --sys 95.out.spacy --ref test.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "for N in `seq 1 10` ; do\n",
    "    fairseq-interactive --path save95/checkpoint10.pt --beam $N data95 < test.sub.ja | grep '^H' | cut -f3 | sed -r 's/(@@ )|(@@ ?$)//g' > 95.$N.out\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    spacy_tokenize(f'95.{i}.out', f'95.{i}.out.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "for N in `seq 1 10` ; do\n",
    "    fairseq-score --sys 95.$N.out.spacy --ref test.en > 95.$N.score\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = range(1, 11)\n",
    "ys = [read_score(f'95.{x}.score') for x in xs]\n",
    "plt.plot(xs, ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 96 学習過程の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.8/site-packages (2.4.1)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp38-cp38-manylinux2010_x86_64.whl (497.6 MB)\n",
      "\u001b[K     |███████████████████▋            | 304.7 MB 96.4 MB/s eta 0:00:03"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 497.6 MB 2.1 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.24.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 64.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 80.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting libclang>=9.0.1\n",
      "  Downloading libclang-13.0.0-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 34.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 37.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Collecting numpy>=1.20\n",
      "  Downloading numpy-1.22.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.8 MB 69.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from tensorflow) (49.6.0.post20210108)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 61.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.15.8)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.29.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.0.1)\n",
      "Installing collected packages: numpy, tf-estimator-nightly, tensorflow-io-gcs-filesystem, tensorboard, libclang, keras, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.4.3\n",
      "    Uninstalling Keras-2.4.3:\n",
      "      Successfully uninstalled Keras-2.4.3\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.4.1\n",
      "    Uninstalling tensorflow-2.4.1:\n",
      "      Successfully uninstalled tensorflow-2.4.1\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Successfully installed keras-2.8.0 libclang-13.0.0 numpy-1.22.2 tensorboard-2.8.0 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.8/site-packages (2.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (0.6.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (1.8.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (1.32.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (1.22.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (49.6.0.post20210108)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (0.4.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (1.29.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (2.25.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (0.36.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (3.15.8)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from absl-py>=0.4->tensorboard) (1.15.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.0.1)\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.8/site-packages (2.8.0)\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
      "\u001b[K     |████████████████████████████████| 124 kB 6.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (1.29.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (1.22.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (0.4.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (49.6.0.post20210108)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (0.6.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (1.8.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (3.15.8)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (1.32.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (2.25.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (0.36.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from absl-py>=0.4->tensorboard) (1.15.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.0.1)\n",
      "Installing collected packages: tensorboardX\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Successfully installed tensorboardX-2.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!fairseq-train data95 \\\n",
    "    --fp16 \\\n",
    "    --tensorboard-logdir log96 \\\n",
    "    --save-dir save96 \\\n",
    "    --max-epoch 5 \\\n",
    "    --arch transformer --share-decoder-input-output-embed \\\n",
    "    --optimizer adam --clip-norm 1.0 \\\n",
    "    --lr 1e-3 --lr-scheduler inverse_sqrt --warmup-updates 2000 \\\n",
    "    --dropout 0.2 --weight-decay 0.0001 \\\n",
    "    --update-freq 1 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 8000 > 96.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-62eb935df33dce11\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-62eb935df33dce11\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir log96 --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://localhost:6006/ でTensorflowの可視化を閲覧できる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 97 ハイパー・パラメータの調整  \n",
    "とりあえずドロップアウト率をいじってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "epoch 001: 100%|▉| 234/235 [02:16<00:00,  1.74it/s, loss=11.52, nll_loss=11.076,\n",
      "epoch 001 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.95s/it]\u001b[A\n",
      "epoch 002: 100%|▉| 234/235 [02:14<00:00,  1.74it/s, loss=9.983, nll_loss=9.279, \u001b[A\n",
      "epoch 002 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n",
      "epoch 003: 100%|▉| 234/235 [02:15<00:00,  1.74it/s, loss=8.415, nll_loss=7.427, \u001b[A\n",
      "epoch 003 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.87s/it]\u001b[A\n",
      "epoch 004: 100%|▉| 234/235 [02:14<00:00,  1.76it/s, loss=7.607, nll_loss=6.478, \u001b[A\n",
      "epoch 004 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  2.00s/it]\u001b[A\n",
      "epoch 005: 100%|▉| 234/235 [02:14<00:00,  1.77it/s, loss=6.91, nll_loss=5.664, p\u001b[A\n",
      "epoch 005 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n",
      "epoch 006: 100%|▉| 234/235 [02:14<00:00,  1.74it/s, loss=6.222, nll_loss=4.868, \u001b[A\n",
      "epoch 006 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 006 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n",
      "epoch 007: 100%|▉| 234/235 [02:15<00:00,  1.75it/s, loss=5.808, nll_loss=4.392, \u001b[A\n",
      "epoch 007 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 007 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.89s/it]\u001b[A\n",
      "epoch 008: 100%|▉| 234/235 [02:14<00:00,  1.74it/s, loss=5.476, nll_loss=4.011, \u001b[A\n",
      "epoch 008 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 008 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.94s/it]\u001b[A\n",
      "epoch 009: 100%|▉| 234/235 [02:14<00:00,  1.77it/s, loss=5.146, nll_loss=3.638, \u001b[A\n",
      "epoch 009 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 009 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.86s/it]\u001b[A\n",
      "epoch 010: 100%|▉| 234/235 [02:14<00:00,  1.76it/s, loss=4.95, nll_loss=3.416, p\u001b[A\n",
      "epoch 010 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 010 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.91s/it]\u001b[A\n",
      "/opt/conda/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 160 leaked semaphore objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    }
   ],
   "source": [
    "!fairseq-train data95 \\\n",
    "    --fp16 \\\n",
    "    --save-dir save97_1 \\\n",
    "    --max-epoch 10 \\\n",
    "    --arch transformer --share-decoder-input-output-embed \\\n",
    "    --optimizer adam --clip-norm 1.0 \\\n",
    "    --lr 1e-3 --lr-scheduler inverse_sqrt --warmup-updates 2000 \\\n",
    "    --dropout 0.1 --weight-decay 0.0001 \\\n",
    "    --update-freq 1 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 8000 > 97_1.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "epoch 001: 100%|▉| 234/235 [02:17<00:00,  1.74it/s, loss=11.654, nll_loss=11.223\n",
      "epoch 001 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.90s/it]\u001b[A\n",
      "epoch 002: 100%|▉| 234/235 [02:15<00:00,  1.73it/s, loss=10.388, nll_loss=9.74, \u001b[A\n",
      "epoch 002 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.90s/it]\u001b[A\n",
      "epoch 003: 100%|▉| 234/235 [02:15<00:00,  1.74it/s, loss=8.881, nll_loss=7.957, \u001b[A\n",
      "epoch 003 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.90s/it]\u001b[A\n",
      "epoch 004: 100%|▉| 234/235 [02:14<00:00,  1.76it/s, loss=8.234, nll_loss=7.192, \u001b[A\n",
      "epoch 004 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n",
      "epoch 005: 100%|▉| 234/235 [02:15<00:00,  1.77it/s, loss=7.756, nll_loss=6.629, \u001b[A\n",
      "epoch 005 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.94s/it]\u001b[A\n",
      "epoch 006: 100%|▉| 234/235 [02:15<00:00,  1.74it/s, loss=7.236, nll_loss=6.024, \u001b[A\n",
      "epoch 006 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 006 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n",
      "epoch 007: 100%|▉| 234/235 [02:14<00:00,  1.76it/s, loss=6.961, nll_loss=5.705, \u001b[A\n",
      "epoch 007 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 007 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.99s/it]\u001b[A\n",
      "epoch 008: 100%|▉| 234/235 [02:15<00:00,  1.73it/s, loss=6.695, nll_loss=5.399, \u001b[A\n",
      "epoch 008 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 008 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.87s/it]\u001b[A\n",
      "epoch 009: 100%|▉| 234/235 [02:14<00:00,  1.78it/s, loss=6.271, nll_loss=4.916, \u001b[A\n",
      "epoch 009 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 009 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n",
      "epoch 010: 100%|▉| 234/235 [02:14<00:00,  1.77it/s, loss=5.962, nll_loss=4.565, \u001b[A\n",
      "epoch 010 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 010 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n",
      "/opt/conda/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 160 leaked semaphore objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    }
   ],
   "source": [
    "!fairseq-train data95 \\\n",
    "    --fp16 \\\n",
    "    --save-dir save97_3 \\\n",
    "    --max-epoch 10 \\\n",
    "    --arch transformer --share-decoder-input-output-embed \\\n",
    "    --optimizer adam --clip-norm 1.0 \\\n",
    "    --lr 1e-3 --lr-scheduler inverse_sqrt --warmup-updates 2000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --update-freq 1 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 8000 > 97_3.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "epoch 001: 100%|▉| 234/235 [02:17<00:00,  1.75it/s, loss=11.776, nll_loss=11.357\n",
      "epoch 001 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.90s/it]\u001b[A\n",
      "epoch 002: 100%|▉| 234/235 [02:14<00:00,  1.74it/s, loss=11.017, nll_loss=10.461\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.96s/it]\u001b[A\n",
      "epoch 003: 100%|▉| 234/235 [02:15<00:00,  1.73it/s, loss=9.428, nll_loss=8.586, \u001b[A\n",
      "epoch 003 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.93s/it]\u001b[A\n",
      "epoch 004: 100%|▉| 234/235 [02:15<00:00,  1.76it/s, loss=8.801, nll_loss=7.847, \u001b[A\n",
      "epoch 004 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.95s/it]\u001b[A\n",
      "epoch 005: 100%|▉| 234/235 [02:15<00:00,  1.77it/s, loss=8.347, nll_loss=7.312, \u001b[A\n",
      "epoch 005 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.92s/it]\u001b[A\n",
      "epoch 006: 100%|▉| 234/235 [02:15<00:00,  1.75it/s, loss=7.823, nll_loss=6.703, \u001b[A\n",
      "epoch 006 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 006 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.98s/it]\u001b[A\n",
      "epoch 007: 100%|▉| 234/235 [02:14<00:00,  1.75it/s, loss=7.519, nll_loss=6.351, \u001b[A\n",
      "epoch 007 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 007 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.94s/it]\u001b[A\n",
      "epoch 008: 100%|▉| 234/235 [02:14<00:00,  1.74it/s, loss=7.303, nll_loss=6.103, \u001b[A\n",
      "epoch 008 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 008 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.97s/it]\u001b[A\n",
      "epoch 009: 100%|▉| 234/235 [02:14<00:00,  1.78it/s, loss=7.042, nll_loss=5.806, \u001b[A\n",
      "epoch 009 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 009 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.94s/it]\u001b[A\n",
      "epoch 010: 100%|▉| 234/235 [02:14<00:00,  1.77it/s, loss=6.893, nll_loss=5.635, \u001b[A\n",
      "epoch 010 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 010 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.88s/it]\u001b[A\n",
      "/opt/conda/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 160 leaked semaphore objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    }
   ],
   "source": [
    "!fairseq-train data95 \\\n",
    "    --fp16 \\\n",
    "    --save-dir save97_5 \\\n",
    "    --max-epoch 10 \\\n",
    "    --arch transformer --share-decoder-input-output-embed \\\n",
    "    --optimizer adam --clip-norm 1.0 \\\n",
    "    --lr 1e-3 --lr-scheduler inverse_sqrt --warmup-updates 2000 \\\n",
    "    --dropout 0.5 --weight-decay 0.0001 \\\n",
    "    --update-freq 1 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 8000 > 97_5.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fairseq-interactive --path save97_1/checkpoint10.pt data95 < test.sub.ja | grep '^H' | cut -f3 | sed -r 's/(@@ )|(@@ ?$)//g' > 97_1.out\n",
    "!fairseq-interactive --path save97_3/checkpoint10.pt data95 < test.sub.ja | grep '^H' | cut -f3 | sed -r 's/(@@ )|(@@ ?$)//g' > 97_3.out\n",
    "!fairseq-interactive --path save97_5/checkpoint10.pt data95 < test.sub.ja | grep '^H' | cut -f3 | sed -r 's/(@@ )|(@@ ?$)//g' > 97_5.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tokenize('97_1.out', '97_1.out.spacy')\n",
    "spacy_tokenize('97_3.out', '97_3.out.spacy')\n",
    "spacy_tokenize('97_5.out', '97_5.out.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(ignore_case=False, order=4, ref='test.en', sacrebleu=False, sentence_bleu=False, sys='97_1.out.spacy')\n",
      "BLEU4 = 19.97, 50.7/24.6/14.3/8.9 (BP=1.000, ratio=1.041, syslen=28782, reflen=27636)\n",
      "Namespace(ignore_case=False, order=4, ref='test.en', sacrebleu=False, sentence_bleu=False, sys='97_3.out.spacy')\n",
      "BLEU4 = 14.57, 41.0/18.3/10.1/6.0 (BP=1.000, ratio=1.159, syslen=32021, reflen=27636)\n",
      "Namespace(ignore_case=False, order=4, ref='test.en', sacrebleu=False, sentence_bleu=False, sys='97_5.out.spacy')\n",
      "BLEU4 = 4.13, 21.8/5.7/2.2/1.0 (BP=1.000, ratio=1.419, syslen=39210, reflen=27636)\n"
     ]
    }
   ],
   "source": [
    "!fairseq-score --sys 97_1.out.spacy --ref test.en\n",
    "!fairseq-score --sys 97_3.out.spacy --ref test.en\n",
    "!fairseq-score --sys 97_5.out.spacy --ref test.en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習率をいじる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "epoch 001: 100%|▉| 234/235 [02:20<00:00,  1.71it/s, loss=11.862, nll_loss=11.488\n",
      "epoch 001 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.17s/it]\u001b[A\n",
      "epoch 002: 100%|▉| 234/235 [02:18<00:00,  1.70it/s, loss=10.674, nll_loss=10.088\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.22s/it]\u001b[A\n",
      "epoch 003: 100%|▉| 234/235 [02:18<00:00,  1.70it/s, loss=9.152, nll_loss=8.303, \u001b[A\n",
      "epoch 003 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.19s/it]\u001b[A\n",
      "epoch 004: 100%|▉| 234/235 [02:18<00:00,  1.72it/s, loss=8.458, nll_loss=7.485, \u001b[A\n",
      "epoch 004 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.18s/it]\u001b[A\n",
      "epoch 005: 100%|▉| 234/235 [02:18<00:00,  1.73it/s, loss=7.834, nll_loss=6.752, \u001b[A\n",
      "epoch 005 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.26s/it]\u001b[A\n",
      "epoch 006: 100%|▉| 234/235 [02:18<00:00,  1.70it/s, loss=7.027, nll_loss=5.805, \u001b[A\n",
      "epoch 006 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 006 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.25s/it]\u001b[A\n",
      "epoch 007: 100%|▉| 234/235 [02:18<00:00,  1.71it/s, loss=6.581, nll_loss=5.286, \u001b[A\n",
      "epoch 007 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 007 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.17s/it]\u001b[A\n",
      "epoch 008: 100%|▉| 234/235 [02:18<00:00,  1.70it/s, loss=6.201, nll_loss=4.846, \u001b[A\n",
      "epoch 008 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 008 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.21s/it]\u001b[A\n",
      "epoch 009: 100%|▉| 234/235 [02:17<00:00,  1.73it/s, loss=5.756, nll_loss=4.334, \u001b[A\n",
      "epoch 009 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 009 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.22s/it]\u001b[A\n",
      "epoch 010: 100%|▉| 234/235 [02:17<00:00,  1.74it/s, loss=5.502, nll_loss=4.042, \u001b[A\n",
      "epoch 010 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 010 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.23s/it]\u001b[A\n",
      "/opt/conda/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 160 leaked semaphore objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    }
   ],
   "source": [
    "!fairseq-train data95 \\\n",
    "    --fp16 \\\n",
    "    --save-dir save97a \\\n",
    "    --max-epoch 10 \\\n",
    "    --arch transformer --share-decoder-input-output-embed \\\n",
    "    --optimizer adam --clip-norm 1.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 2000 \\\n",
    "    --dropout 0.1 --weight-decay 0.0001 \\\n",
    "    --update-freq 1 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 8000 > 97a.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fairseq-interactive --path save97a/checkpoint10.pt data95 < test.sub.ja | grep '^H' | cut -f3 | sed -r 's/(@@ )|(@@ ?$)//g' > 97a.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tokenize('97a.out', '97a.out.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fairseq-score --sys 97a.out.spacy --ref test.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "epoch 001: 100%|▉| 234/235 [02:18<00:00,  1.73it/s, loss=12.437, nll_loss=12.142\n",
      "epoch 001 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.24s/it]\u001b[A\n",
      "epoch 002: 100%|▉| 234/235 [02:16<00:00,  1.74it/s, loss=11.327, nll_loss=10.857\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.21s/it]\u001b[A\n",
      "epoch 003: 100%|▉| 234/235 [02:16<00:00,  1.73it/s, loss=10.176, nll_loss=9.512,\u001b[A\n",
      "epoch 003 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.17s/it]\u001b[A\n",
      "epoch 004: 100%|▉| 234/235 [02:15<00:00,  1.74it/s, loss=9.483, nll_loss=8.701, \u001b[A\n",
      "epoch 004 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.18s/it]\u001b[A\n",
      "epoch 005: 100%|▉| 234/235 [02:16<00:00,  1.76it/s, loss=8.967, nll_loss=8.091, \u001b[A\n",
      "epoch 005 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.20s/it]\u001b[A\n",
      "epoch 006: 100%|▉| 234/235 [02:15<00:00,  1.73it/s, loss=8.337, nll_loss=7.347, \u001b[A\n",
      "epoch 006 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 006 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.18s/it]\u001b[A\n",
      "                                                                                \u001b[Aterminate called after throwing an instance of 'c10::Error'\n",
      "  what():  [enforce fail at inline_container.cc:274] . unexpected pos 397839616 vs 397839504\n",
      "frame #0: c10::ThrowEnforceNotMet(char const*, int, char const*, std::string const&, void const*) + 0x47 (0x7fd465b4c0e7 in /opt/conda/lib/python3.8/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x206a420 (0x7fd435073420 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x20665f3 (0x7fd43506f5f3 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: caffe2::serialize::PyTorchStreamWriter::writeRecord(std::string const&, void const*, unsigned long, bool) + 0xa9 (0x7fd435073d99 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: caffe2::serialize::PyTorchStreamWriter::writeEndOfFile() + 0xe1 (0x7fd4350748d1 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: caffe2::serialize::PyTorchStreamWriter::~PyTorchStreamWriter() + 0x115 (0x7fd4350750c5 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #6: <unknown function> + 0x737903 (0x7fd4666f6903 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #7: <unknown function> + 0x369b90 (0x7fd466328b90 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #8: <unknown function> + 0x36adfe (0x7fd466329dfe in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #9: <unknown function> + 0xfb138 (0x560d01c6b138 in /opt/conda/bin/python3.8)\n",
      "frame #10: <unknown function> + 0xfd788 (0x560d01c6d788 in /opt/conda/bin/python3.8)\n",
      "frame #11: <unknown function> + 0xfd829 (0x560d01c6d829 in /opt/conda/bin/python3.8)\n",
      "frame #12: _PyEval_EvalFrameDefault + 0x2724 (0x560d01d42344 in /opt/conda/bin/python3.8)\n",
      "frame #13: _PyFunction_Vectorcall + 0x1a6 (0x560d01d21706 in /opt/conda/bin/python3.8)\n",
      "frame #14: _PyEval_EvalFrameDefault + 0x92f (0x560d01d4054f in /opt/conda/bin/python3.8)\n",
      "frame #15: _PyEval_EvalCodeWithName + 0x2c3 (0x560d01d20503 in /opt/conda/bin/python3.8)\n",
      "frame #16: _PyFunction_Vectorcall + 0x378 (0x560d01d218d8 in /opt/conda/bin/python3.8)\n",
      "frame #17: _PyEval_EvalFrameDefault + 0x4ca3 (0x560d01d448c3 in /opt/conda/bin/python3.8)\n",
      "frame #18: _PyFunction_Vectorcall + 0x1a6 (0x560d01d21706 in /opt/conda/bin/python3.8)\n",
      "frame #19: _PyEval_EvalFrameDefault + 0xa4b (0x560d01d4066b in /opt/conda/bin/python3.8)\n",
      "frame #20: _PyEval_EvalCodeWithName + 0x2c3 (0x560d01d20503 in /opt/conda/bin/python3.8)\n",
      "frame #21: _PyFunction_Vectorcall + 0x378 (0x560d01d218d8 in /opt/conda/bin/python3.8)\n",
      "frame #22: _PyEval_EvalFrameDefault + 0x4ca3 (0x560d01d448c3 in /opt/conda/bin/python3.8)\n",
      "frame #23: _PyFunction_Vectorcall + 0x1a6 (0x560d01d21706 in /opt/conda/bin/python3.8)\n",
      "frame #24: _PyEval_EvalFrameDefault + 0x92f (0x560d01d4054f in /opt/conda/bin/python3.8)\n",
      "frame #25: _PyFunction_Vectorcall + 0x1a6 (0x560d01d21706 in /opt/conda/bin/python3.8)\n",
      "frame #26: PyObject_Call + 0x5e (0x560d01c950be in /opt/conda/bin/python3.8)\n",
      "frame #27: _PyEval_EvalFrameDefault + 0x21c1 (0x560d01d41de1 in /opt/conda/bin/python3.8)\n",
      "frame #28: _PyEval_EvalCodeWithName + 0x2c3 (0x560d01d20503 in /opt/conda/bin/python3.8)\n",
      "frame #29: _PyFunction_Vectorcall + 0x378 (0x560d01d218d8 in /opt/conda/bin/python3.8)\n",
      "frame #30: _PyEval_EvalFrameDefault + 0x92f (0x560d01d4054f in /opt/conda/bin/python3.8)\n",
      "frame #31: _PyFunction_Vectorcall + 0x1a6 (0x560d01d21706 in /opt/conda/bin/python3.8)\n",
      "frame #32: PyObject_Call + 0x5e (0x560d01c950be in /opt/conda/bin/python3.8)\n",
      "frame #33: _PyEval_EvalFrameDefault + 0x21c1 (0x560d01d41de1 in /opt/conda/bin/python3.8)\n",
      "frame #34: _PyFunction_Vectorcall + 0x1a6 (0x560d01d21706 in /opt/conda/bin/python3.8)\n",
      "frame #35: PyObject_Call + 0x5e (0x560d01c950be in /opt/conda/bin/python3.8)\n",
      "frame #36: _PyEval_EvalFrameDefault + 0x21c1 (0x560d01d41de1 in /opt/conda/bin/python3.8)\n",
      "frame #37: _PyFunction_Vectorcall + 0x1a6 (0x560d01d21706 in /opt/conda/bin/python3.8)\n",
      "frame #38: PyObject_Call + 0x5e (0x560d01c950be in /opt/conda/bin/python3.8)\n",
      "frame #39: _PyEval_EvalFrameDefault + 0x21c1 (0x560d01d41de1 in /opt/conda/bin/python3.8)\n",
      "frame #40: _PyFunction_Vectorcall + 0x1a6 (0x560d01d21706 in /opt/conda/bin/python3.8)\n",
      "frame #41: _PyEval_EvalFrameDefault + 0xa4b (0x560d01d4066b in /opt/conda/bin/python3.8)\n",
      "frame #42: _PyEval_EvalCodeWithName + 0x2c3 (0x560d01d20503 in /opt/conda/bin/python3.8)\n",
      "frame #43: _PyFunction_Vectorcall + 0x378 (0x560d01d218d8 in /opt/conda/bin/python3.8)\n",
      "frame #44: _PyEval_EvalFrameDefault + 0xa4b (0x560d01d4066b in /opt/conda/bin/python3.8)\n",
      "frame #45: _PyFunction_Vectorcall + 0x1a6 (0x560d01d21706 in /opt/conda/bin/python3.8)\n",
      "frame #46: _PyEval_EvalFrameDefault + 0x92f (0x560d01d4054f in /opt/conda/bin/python3.8)\n",
      "frame #47: _PyEval_EvalCodeWithName + 0x2c3 (0x560d01d20503 in /opt/conda/bin/python3.8)\n",
      "frame #48: _PyFunction_Vectorcall + 0x378 (0x560d01d218d8 in /opt/conda/bin/python3.8)\n",
      "frame #49: _PyEval_EvalFrameDefault + 0x1782 (0x560d01d413a2 in /opt/conda/bin/python3.8)\n",
      "frame #50: _PyEval_EvalCodeWithName + 0x2c3 (0x560d01d20503 in /opt/conda/bin/python3.8)\n",
      "frame #51: PyEval_EvalCodeEx + 0x39 (0x560d01d21559 in /opt/conda/bin/python3.8)\n",
      "frame #52: PyEval_EvalCode + 0x1b (0x560d01dc49ab in /opt/conda/bin/python3.8)\n",
      "frame #53: <unknown function> + 0x254a43 (0x560d01dc4a43 in /opt/conda/bin/python3.8)\n",
      "frame #54: <unknown function> + 0x26e6b3 (0x560d01dde6b3 in /opt/conda/bin/python3.8)\n",
      "frame #55: PyRun_StringFlags + 0x7d (0x560d01de2dfd in /opt/conda/bin/python3.8)\n",
      "frame #56: PyRun_SimpleStringFlags + 0x3d (0x560d01de2e5d in /opt/conda/bin/python3.8)\n",
      "frame #57: Py_RunMain + 0x158 (0x560d01de3af8 in /opt/conda/bin/python3.8)\n",
      "frame #58: Py_BytesMain + 0x39 (0x560d01de3ec9 in /opt/conda/bin/python3.8)\n",
      "frame #59: __libc_start_main + 0xf3 (0x7fd46deab0b3 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #60: <unknown function> + 0x1e9369 (0x560d01d59369 in /opt/conda/bin/python3.8)\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/fairseq-train\", line 8, in <module>\n",
      "    sys.exit(cli_main())\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq_cli/train.py\", line 352, in cli_main\n",
      "    distributed_utils.call_main(args, main)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq/distributed_utils.py\", line 283, in call_main\n",
      "    torch.multiprocessing.spawn(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\", line 230, in spawn\n",
      "    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\", line 188, in start_processes\n",
      "    while not context.join():\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\", line 130, in join\n",
      "    raise ProcessExitedException(\n",
      "torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGABRT\n"
     ]
    }
   ],
   "source": [
    "!fairseq-train data95 \\\n",
    "    --fp16 \\\n",
    "    --save-dir save97b \\\n",
    "    --max-epoch 10 \\\n",
    "    --arch transformer --share-decoder-input-output-embed \\\n",
    "    --optimizer adam --clip-norm 1.0 \\\n",
    "    --lr 2e-4 --lr-scheduler inverse_sqrt --warmup-updates 2000 \\\n",
    "    --dropout 0.1 --weight-decay 0.0001 \\\n",
    "    --update-freq 1 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 8000 > 97b.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fairseq-interactive --path save97b/checkpoint10.pt data95 < test.sub.ja | grep '^H' | cut -f3 | sed -r 's/(@@ )|(@@ ?$)//g' > 97b.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tokenize('97b.out', '97b.out.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fairseq-score --sys 97b.out.spacy --ref test.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "epoch 001: 100%|▉| 234/235 [02:20<00:00,  1.72it/s, loss=12.796, nll_loss=12.539\n",
      "epoch 001 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.21s/it]\u001b[A\n",
      "                                                                                \u001b[Aterminate called after throwing an instance of 'c10::Error'\n",
      "  what():  [enforce fail at inline_container.cc:274] . unexpected pos 1109568 vs 1109456\n",
      "frame #0: c10::ThrowEnforceNotMet(char const*, int, char const*, std::string const&, void const*) + 0x47 (0x7fac299a60e7 in /opt/conda/lib/python3.8/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x206a420 (0x7fabf6e78420 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x20665f3 (0x7fabf6e745f3 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: caffe2::serialize::PyTorchStreamWriter::writeRecord(std::string const&, void const*, unsigned long, bool) + 0xa9 (0x7fabf6e78d99 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: caffe2::serialize::PyTorchStreamWriter::writeEndOfFile() + 0xe1 (0x7fabf6e798d1 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: caffe2::serialize::PyTorchStreamWriter::~PyTorchStreamWriter() + 0x115 (0x7fabf6e7a0c5 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #6: <unknown function> + 0x737903 (0x7fac2a96b903 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #7: <unknown function> + 0x369b90 (0x7fac2a59db90 in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #8: <unknown function> + 0x36adfe (0x7fac2a59edfe in /opt/conda/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #9: <unknown function> + 0xfb138 (0x5623f80cf138 in /opt/conda/bin/python3.8)\n",
      "frame #10: <unknown function> + 0xfd788 (0x5623f80d1788 in /opt/conda/bin/python3.8)\n",
      "frame #11: <unknown function> + 0xfd829 (0x5623f80d1829 in /opt/conda/bin/python3.8)\n",
      "frame #12: _PyEval_EvalFrameDefault + 0x2724 (0x5623f81a6344 in /opt/conda/bin/python3.8)\n",
      "frame #13: _PyFunction_Vectorcall + 0x1a6 (0x5623f8185706 in /opt/conda/bin/python3.8)\n",
      "frame #14: _PyEval_EvalFrameDefault + 0x92f (0x5623f81a454f in /opt/conda/bin/python3.8)\n",
      "frame #15: _PyEval_EvalCodeWithName + 0x2c3 (0x5623f8184503 in /opt/conda/bin/python3.8)\n",
      "frame #16: _PyFunction_Vectorcall + 0x378 (0x5623f81858d8 in /opt/conda/bin/python3.8)\n",
      "frame #17: _PyEval_EvalFrameDefault + 0x4ca3 (0x5623f81a88c3 in /opt/conda/bin/python3.8)\n",
      "frame #18: _PyFunction_Vectorcall + 0x1a6 (0x5623f8185706 in /opt/conda/bin/python3.8)\n",
      "frame #19: _PyEval_EvalFrameDefault + 0xa4b (0x5623f81a466b in /opt/conda/bin/python3.8)\n",
      "frame #20: _PyEval_EvalCodeWithName + 0x2c3 (0x5623f8184503 in /opt/conda/bin/python3.8)\n",
      "frame #21: _PyFunction_Vectorcall + 0x378 (0x5623f81858d8 in /opt/conda/bin/python3.8)\n",
      "frame #22: _PyEval_EvalFrameDefault + 0x4ca3 (0x5623f81a88c3 in /opt/conda/bin/python3.8)\n",
      "frame #23: _PyFunction_Vectorcall + 0x1a6 (0x5623f8185706 in /opt/conda/bin/python3.8)\n",
      "frame #24: _PyEval_EvalFrameDefault + 0x92f (0x5623f81a454f in /opt/conda/bin/python3.8)\n",
      "frame #25: _PyFunction_Vectorcall + 0x1a6 (0x5623f8185706 in /opt/conda/bin/python3.8)\n",
      "frame #26: PyObject_Call + 0x5e (0x5623f80f90be in /opt/conda/bin/python3.8)\n",
      "frame #27: _PyEval_EvalFrameDefault + 0x21c1 (0x5623f81a5de1 in /opt/conda/bin/python3.8)\n",
      "frame #28: _PyEval_EvalCodeWithName + 0x2c3 (0x5623f8184503 in /opt/conda/bin/python3.8)\n",
      "frame #29: _PyFunction_Vectorcall + 0x378 (0x5623f81858d8 in /opt/conda/bin/python3.8)\n",
      "frame #30: _PyEval_EvalFrameDefault + 0x92f (0x5623f81a454f in /opt/conda/bin/python3.8)\n",
      "frame #31: _PyFunction_Vectorcall + 0x1a6 (0x5623f8185706 in /opt/conda/bin/python3.8)\n",
      "frame #32: PyObject_Call + 0x5e (0x5623f80f90be in /opt/conda/bin/python3.8)\n",
      "frame #33: _PyEval_EvalFrameDefault + 0x21c1 (0x5623f81a5de1 in /opt/conda/bin/python3.8)\n",
      "frame #34: _PyFunction_Vectorcall + 0x1a6 (0x5623f8185706 in /opt/conda/bin/python3.8)\n",
      "frame #35: PyObject_Call + 0x5e (0x5623f80f90be in /opt/conda/bin/python3.8)\n",
      "frame #36: _PyEval_EvalFrameDefault + 0x21c1 (0x5623f81a5de1 in /opt/conda/bin/python3.8)\n",
      "frame #37: _PyFunction_Vectorcall + 0x1a6 (0x5623f8185706 in /opt/conda/bin/python3.8)\n",
      "frame #38: PyObject_Call + 0x5e (0x5623f80f90be in /opt/conda/bin/python3.8)\n",
      "frame #39: _PyEval_EvalFrameDefault + 0x21c1 (0x5623f81a5de1 in /opt/conda/bin/python3.8)\n",
      "frame #40: _PyFunction_Vectorcall + 0x1a6 (0x5623f8185706 in /opt/conda/bin/python3.8)\n",
      "frame #41: _PyEval_EvalFrameDefault + 0xa4b (0x5623f81a466b in /opt/conda/bin/python3.8)\n",
      "frame #42: _PyEval_EvalCodeWithName + 0x2c3 (0x5623f8184503 in /opt/conda/bin/python3.8)\n",
      "frame #43: _PyFunction_Vectorcall + 0x378 (0x5623f81858d8 in /opt/conda/bin/python3.8)\n",
      "frame #44: _PyEval_EvalFrameDefault + 0xa4b (0x5623f81a466b in /opt/conda/bin/python3.8)\n",
      "frame #45: _PyFunction_Vectorcall + 0x1a6 (0x5623f8185706 in /opt/conda/bin/python3.8)\n",
      "frame #46: _PyEval_EvalFrameDefault + 0x92f (0x5623f81a454f in /opt/conda/bin/python3.8)\n",
      "frame #47: _PyEval_EvalCodeWithName + 0x2c3 (0x5623f8184503 in /opt/conda/bin/python3.8)\n",
      "frame #48: _PyFunction_Vectorcall + 0x378 (0x5623f81858d8 in /opt/conda/bin/python3.8)\n",
      "frame #49: _PyEval_EvalFrameDefault + 0x1782 (0x5623f81a53a2 in /opt/conda/bin/python3.8)\n",
      "frame #50: _PyEval_EvalCodeWithName + 0x2c3 (0x5623f8184503 in /opt/conda/bin/python3.8)\n",
      "frame #51: PyEval_EvalCodeEx + 0x39 (0x5623f8185559 in /opt/conda/bin/python3.8)\n",
      "frame #52: PyEval_EvalCode + 0x1b (0x5623f82289ab in /opt/conda/bin/python3.8)\n",
      "frame #53: <unknown function> + 0x254a43 (0x5623f8228a43 in /opt/conda/bin/python3.8)\n",
      "frame #54: <unknown function> + 0x26e6b3 (0x5623f82426b3 in /opt/conda/bin/python3.8)\n",
      "frame #55: PyRun_StringFlags + 0x7d (0x5623f8246dfd in /opt/conda/bin/python3.8)\n",
      "frame #56: PyRun_SimpleStringFlags + 0x3d (0x5623f8246e5d in /opt/conda/bin/python3.8)\n",
      "frame #57: Py_RunMain + 0x158 (0x5623f8247af8 in /opt/conda/bin/python3.8)\n",
      "frame #58: Py_BytesMain + 0x39 (0x5623f8247ec9 in /opt/conda/bin/python3.8)\n",
      "frame #59: __libc_start_main + 0xf3 (0x7fac2fcb00b3 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #60: <unknown function> + 0x1e9369 (0x5623f81bd369 in /opt/conda/bin/python3.8)\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "_pickle.UnpicklingError: pickle data was truncated\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/fairseq-train\", line 8, in <module>\n",
      "    sys.exit(cli_main())\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq_cli/train.py\", line 352, in cli_main\n",
      "    distributed_utils.call_main(args, main)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq/distributed_utils.py\", line 283, in call_main\n",
      "    torch.multiprocessing.spawn(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\", line 230, in spawn\n",
      "    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\", line 188, in start_processes\n",
      "    while not context.join():\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\", line 130, in join\n",
      "    raise ProcessExitedException(\n",
      "torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGABRT\n"
     ]
    }
   ],
   "source": [
    "!fairseq-train data95 \\\n",
    "    --fp16 \\\n",
    "    --save-dir save97c \\\n",
    "    --max-epoch 10 \\\n",
    "    --arch transformer --share-decoder-input-output-embed \\\n",
    "    --optimizer adam --clip-norm 1.0 \\\n",
    "    --lr 1e-4 --lr-scheduler inverse_sqrt --warmup-updates 2000 \\\n",
    "    --dropout 0.1 --weight-decay 0.0001 \\\n",
    "    --update-freq 1 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 8000 > 97c.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/fairseq-interactive\", line 8, in <module>\n",
      "    sys.exit(cli_main())\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq_cli/interactive.py\", line 307, in cli_main\n",
      "    distributed_utils.call_main(args, main)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq/distributed_utils.py\", line 301, in call_main\n",
      "    main(args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq_cli/interactive.py\", line 143, in main\n",
      "    models, _model_args = checkpoint_utils.load_model_ensemble(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq/checkpoint_utils.py\", line 250, in load_model_ensemble\n",
      "    ensemble, args, _task = load_model_ensemble_and_task(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq/checkpoint_utils.py\", line 278, in load_model_ensemble_and_task\n",
      "    raise IOError(\"Model file not found: {}\".format(filename))\n",
      "OSError: Model file not found: save97b/checkpoint10.pt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/fairseq-interactive\", line 8, in <module>\n",
      "    sys.exit(cli_main())\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq_cli/interactive.py\", line 307, in cli_main\n",
      "    distributed_utils.call_main(args, main)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq/distributed_utils.py\", line 301, in call_main\n",
      "    main(args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq_cli/interactive.py\", line 143, in main\n",
      "    models, _model_args = checkpoint_utils.load_model_ensemble(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq/checkpoint_utils.py\", line 250, in load_model_ensemble\n",
      "    ensemble, args, _task = load_model_ensemble_and_task(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq/checkpoint_utils.py\", line 278, in load_model_ensemble_and_task\n",
      "    raise IOError(\"Model file not found: {}\".format(filename))\n",
      "OSError: Model file not found: save97c/checkpoint10.pt\n"
     ]
    }
   ],
   "source": [
    "!fairseq-interactive --path save97c/checkpoint10.pt data95 < test.sub.ja | grep '^H' | cut -f3 | sed -r 's/(@@ )|(@@ ?$)//g' > 97c.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tokenize('97c.out', '97c.out.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(ignore_case=False, order=4, ref='test.en', sacrebleu=False, sentence_bleu=False, sys='97a.out.spacy')\n",
      "BLEU4 = 17.94, 47.4/22.3/12.6/7.8 (BP=1.000, ratio=1.054, syslen=29116, reflen=27636)\n",
      "Namespace(ignore_case=False, order=4, ref='test.en', sacrebleu=False, sentence_bleu=False, sys='97b.out.spacy')\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/fairseq-score\", line 8, in <module>\n",
      "    sys.exit(cli_main())\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq_cli/score.py\", line 92, in cli_main\n",
      "    score(f)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq_cli/score.py\", line 86, in score\n",
      "    print(scorer.result_string(args.order))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq/scoring/bleu.py\", line 151, in result_string\n",
      "    self.score(order=order),\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq/scoring/bleu.py\", line 125, in score\n",
      "    return self.brevity() * math.exp(psum / order) * 100\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq/scoring/bleu.py\", line 139, in brevity\n",
      "    r = self.stat.reflen / self.stat.predlen\n",
      "ZeroDivisionError: division by zero\n",
      "Namespace(ignore_case=False, order=4, ref='test.en', sacrebleu=False, sentence_bleu=False, sys='97c.out.spacy')\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/fairseq-score\", line 8, in <module>\n",
      "    sys.exit(cli_main())\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq_cli/score.py\", line 92, in cli_main\n",
      "    score(f)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq_cli/score.py\", line 86, in score\n",
      "    print(scorer.result_string(args.order))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq/scoring/bleu.py\", line 151, in result_string\n",
      "    self.score(order=order),\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq/scoring/bleu.py\", line 125, in score\n",
      "    return self.brevity() * math.exp(psum / order) * 100\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fairseq/scoring/bleu.py\", line 139, in brevity\n",
      "    r = self.stat.reflen / self.stat.predlen\n",
      "ZeroDivisionError: division by zero\n"
     ]
    }
   ],
   "source": [
    "!fairseq-score --sys 97c.out.spacy --ref test.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 98 ドメイン適応"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-20 14:55:46--  http://www.kecl.ntt.co.jp/icl/lirg/jparacrawl/release/2.0/bitext/en-ja.tar.gz\n",
      "Resolving www.kecl.ntt.co.jp (www.kecl.ntt.co.jp)... 163.137.218.58\n",
      "Connecting to www.kecl.ntt.co.jp (www.kecl.ntt.co.jp)|163.137.218.58|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1294917545 (1.2G) [application/x-gzip]\n",
      "Saving to: ‘en-ja.tar.gz’\n",
      "\n",
      "en-ja.tar.gz        100%[===================>]   1.21G  2.30MB/s    in 6m 38s  \n",
      "\n",
      "2022-02-20 15:02:23 (3.10 MB/s) - ‘en-ja.tar.gz’ saved [1294917545/1294917545]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.kecl.ntt.co.jp/icl/lirg/jparacrawl/release/2.0/bitext/en-ja.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tarfile.open('en-ja.tar.gz') as tar:\n",
    "    for f in tar.getmembers():\n",
    "        if f.name.endswith('txt'):\n",
    "            text = tar.extractfile(f).read().decode('utf-8')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = text.splitlines()\n",
    "data = [x.split('\\t') for x in data]\n",
    "data = [x for x in data if len(x) == 4]\n",
    "data = [[x[3], x[2]] for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('jparacrawl.ja', 'w') as f, open('jparacrawl.en', 'w') as g:\n",
    "    for j, e in data:\n",
    "        print(j, file=f)\n",
    "        print(e, file=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('jparacrawl.ja') as f, open('train.jparacrawl.ja', 'w') as g:\n",
    "    for x in f:\n",
    "        x = x.strip()\n",
    "        x = re.sub(r'\\s+', ' ', x)\n",
    "        x = sp.encode_as_pieces(x)\n",
    "        x = ' '.join(x)\n",
    "        print(x, file=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "!subword-nmt apply-bpe -c kyoto_en.codes < jparacrawl.en > train.jparacrawl.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-21 13:02:48 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data98', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=8, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='ja', srcdict=None, target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='train.jparacrawl', user_dir=None, validpref='dev.sub', workers=30)\n",
      "2022-02-21 13:06:18 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 31144 types\n",
      "2022-02-21 13:11:51 | INFO | fairseq_cli.preprocess | [ja] train.jparacrawl.ja: 10120012 sents, 458025194 tokens, 0.0% replaced by <unk>\n",
      "2022-02-21 13:11:51 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 31144 types\n",
      "2022-02-21 13:11:52 | INFO | fairseq_cli.preprocess | [ja] dev.sub.ja: 1166 sents, 24825 tokens, 0.29% replaced by <unk>\n",
      "2022-02-21 13:11:52 | INFO | fairseq_cli.preprocess | [en] Dictionary: 29424 types\n",
      "2022-02-21 13:15:40 | INFO | fairseq_cli.preprocess | [en] train.jparacrawl.en: 10120012 sents, 386654564 tokens, 0.0% replaced by <unk>\n",
      "2022-02-21 13:15:40 | INFO | fairseq_cli.preprocess | [en] Dictionary: 29424 types\n",
      "2022-02-21 13:15:40 | INFO | fairseq_cli.preprocess | [en] dev.sub.en: 1166 sents, 29011 tokens, 0.279% replaced by <unk>\n",
      "2022-02-21 13:15:40 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data98\n"
     ]
    }
   ],
   "source": [
    "!fairseq-preprocess -s ja -t en \\\n",
    "    --trainpref train.jparacrawl \\\n",
    "    --validpref dev.sub \\\n",
    "    --model-parallel-size 8 \\\n",
    "    --destdir data98  \\\n",
    "    --workers 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "epoch 001: 100%|▉| 7796/7797 [1:20:44<00:00,  1.59it/s, loss=6.125, nll_loss=4.7\n",
      "epoch 001 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.29s/it]\u001b[A\n",
      "epoch 002: 100%|▉| 7796/7797 [1:20:46<00:00,  1.56it/s, loss=5.14, nll_loss=3.62\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.29s/it]\u001b[A\n",
      "epoch 003: 100%|▉| 7796/7797 [1:20:50<00:00,  1.61it/s, loss=4.784, nll_loss=3.2\u001b[A\n",
      "epoch 003 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.31s/it]\u001b[A\n",
      "/opt/conda/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    }
   ],
   "source": [
    "!fairseq-train data98 \\\n",
    "    --fp16 \\\n",
    "    --save-dir save98_1 \\\n",
    "    --max-epoch 3 \\\n",
    "    --arch transformer --share-decoder-input-output-embed \\\n",
    "    --optimizer adam --clip-norm 1.0 \\\n",
    "    --lr 1e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.1 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 8000 > 98_1.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fairseq-interactive --path save98_1/checkpoint3.pt data98 < test.sub.ja | grep '^H' | cut -f3 | sed -r 's/(@@ )|(@@ ?$)//g' > 98_1.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tokenize('98_1.out', '98_1.out.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(ignore_case=False, order=4, ref='test.en', sacrebleu=False, sentence_bleu=False, sys='98_1.out.spacy')\n",
      "BLEU4 = 8.57, 41.4/13.8/5.7/2.6 (BP=0.895, ratio=0.900, syslen=24878, reflen=27636)\n"
     ]
    }
   ],
   "source": [
    "!fairseq-score --sys 98_1.out.spacy --ref test.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-21 17:46:04 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data98_2', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=8, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='ja', srcdict='data98/dict.ja.txt', target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict='data98/dict.en.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='train.sub', user_dir=None, validpref='dev.sub', workers=30)\n",
      "2022-02-21 17:46:05 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 31144 types\n",
      "2022-02-21 17:46:15 | INFO | fairseq_cli.preprocess | [ja] train.sub.ja: 440288 sents, 10735573 tokens, 0.239% replaced by <unk>\n",
      "2022-02-21 17:46:15 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 31144 types\n",
      "2022-02-21 17:46:16 | INFO | fairseq_cli.preprocess | [ja] dev.sub.ja: 1166 sents, 24825 tokens, 0.29% replaced by <unk>\n",
      "2022-02-21 17:46:16 | INFO | fairseq_cli.preprocess | [en] Dictionary: 29424 types\n",
      "2022-02-21 17:46:25 | INFO | fairseq_cli.preprocess | [en] train.sub.en: 440288 sents, 13280091 tokens, 0.222% replaced by <unk>\n",
      "2022-02-21 17:46:25 | INFO | fairseq_cli.preprocess | [en] Dictionary: 29424 types\n",
      "2022-02-21 17:46:25 | INFO | fairseq_cli.preprocess | [en] dev.sub.en: 1166 sents, 29011 tokens, 0.279% replaced by <unk>\n",
      "2022-02-21 17:46:25 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data98_2\n"
     ]
    }
   ],
   "source": [
    "!fairseq-preprocess -s ja -t en \\\n",
    "    --trainpref train.sub \\\n",
    "    --validpref dev.sub \\\n",
    "    --tgtdict data98/dict.en.txt \\\n",
    "    --srcdict data98/dict.ja.txt \\\n",
    "    --model-parallel-size 8 \\\n",
    "    --destdir data98_2  \\\n",
    "    --workers 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.\n",
      "  warnings.warn(\n",
      "epoch 004: 100%|▉| 234/235 [02:27<00:00,  1.62it/s, loss=5.825, nll_loss=4.389, \n",
      "epoch 004 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.26s/it]\u001b[A\n",
      "epoch 005: 100%|▉| 234/235 [02:26<00:00,  1.64it/s, loss=5.38, nll_loss=3.878, p\u001b[A\n",
      "epoch 005 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.26s/it]\u001b[A\n",
      "epoch 006: 100%|▉| 234/235 [02:26<00:00,  1.61it/s, loss=5.132, nll_loss=3.594, \u001b[A\n",
      "epoch 006 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 006 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.20s/it]\u001b[A\n",
      "epoch 007: 100%|▉| 234/235 [02:27<00:00,  1.61it/s, loss=4.93, nll_loss=3.363, p\u001b[A\n",
      "epoch 007 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 007 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.28s/it]\u001b[A\n",
      "epoch 008: 100%|▉| 234/235 [02:27<00:00,  1.60it/s, loss=4.805, nll_loss=3.221, \u001b[A\n",
      "epoch 008 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 008 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.22s/it]\u001b[A\n",
      "epoch 009: 100%|▉| 234/235 [02:27<00:00,  1.63it/s, loss=4.698, nll_loss=3.098, \u001b[A\n",
      "epoch 009 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 009 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.27s/it]\u001b[A\n",
      "epoch 010: 100%|▉| 234/235 [02:27<00:00,  1.63it/s, loss=4.603, nll_loss=2.99, p\u001b[A\n",
      "epoch 010 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 010 | valid on 'valid' subset: 100%|████████| 1/1 [00:02<00:00,  2.24s/it]\u001b[A\n",
      "/opt/conda/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 112 leaked semaphore objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    }
   ],
   "source": [
    "!fairseq-train data98_2 \\\n",
    "    --fp16 \\\n",
    "    --restore-file save98_1/checkpoint3.pt \\\n",
    "    --save-dir save98_2 \\\n",
    "    --max-epoch 10 \\\n",
    "    --arch transformer --share-decoder-input-output-embed \\\n",
    "    --optimizer adam --clip-norm 1.0 \\\n",
    "    --lr 1e-3 --lr-scheduler inverse_sqrt --warmup-updates 2000 \\\n",
    "    --dropout 0.1 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 8000 > 98_2.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fairseq-interactive --path save98_2/checkpoint10.pt data98_2 < test.sub.ja | grep '^H' | cut -f3 | sed -r 's/(@@ )|(@@ ?$)//g' > 98_2.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tokenize('98_2.out', '98_2.out.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(ignore_case=False, order=4, ref='test.en', sacrebleu=False, sentence_bleu=False, sys='98_2.out.spacy')\n",
      "BLEU4 = 22.27, 53.2/27.1/16.4/10.4 (BP=1.000, ratio=1.042, syslen=28802, reflen=27636)\n"
     ]
    }
   ],
   "source": [
    "!fairseq-score --sys 98_2.out.spacy --ref test.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
